{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed data: (8457, 79)\n",
      "\n",
      "Target variable encoding:\n",
      "Detract: 0\n",
      "Passive: 1\n",
      "Promote: 2\n",
      "Super Detract: 3\n",
      "\n",
      "First few rows of transformed data:\n",
      "   iag_trust_confidence_scale11_Low  iag_trust_confidence_scale11_Moderate  \\\n",
      "0                               0.0                                    0.0   \n",
      "1                               0.0                                    1.0   \n",
      "2                               0.0                                    0.0   \n",
      "3                               0.0                                    0.0   \n",
      "4                               0.0                                    0.0   \n",
      "\n",
      "   iag_trust_confidence_scale11_High  iag_trust_confidence_scale11_Very High  \\\n",
      "0                                0.0                                     0.0   \n",
      "1                                0.0                                     0.0   \n",
      "2                                1.0                                     0.0   \n",
      "3                                1.0                                     0.0   \n",
      "4                                1.0                                     0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Fair  \\\n",
      "0                                              0.0   \n",
      "1                                              0.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Good  \\\n",
      "0                                              0.0   \n",
      "1                                              1.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Very Good  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Excellent  \\\n",
      "0                                                1.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_business_unit_ug_Operations  iag_age_band_auto_25-34  ...  \\\n",
      "0                              1.0                      0.0  ...   \n",
      "1                              1.0                      0.0  ...   \n",
      "2                              1.0                      0.0  ...   \n",
      "3                              0.0                      0.0  ...   \n",
      "4                              1.0                      0.0  ...   \n",
      "\n",
      "   iag_product_type_auto_Home Pack  iag_product_type_auto_Homeowners Line  \\\n",
      "0                              0.0                                    0.0   \n",
      "1                              1.0                                    0.0   \n",
      "2                              0.0                                    0.0   \n",
      "3                              0.0                                    0.0   \n",
      "4                              0.0                                    0.0   \n",
      "\n",
      "   iag_product_type_auto_Jetsetter  iag_product_type_auto_Landlord  \\\n",
      "0                              0.0                             0.0   \n",
      "1                              0.0                             0.0   \n",
      "2                              0.0                             0.0   \n",
      "3                              0.0                             0.0   \n",
      "4                              0.0                             0.0   \n",
      "\n",
      "   iag_product_type_auto_Private Motor Line  iag_product_type_auto_Vehicle  \\\n",
      "0                                       0.0                            1.0   \n",
      "1                                       0.0                            0.0   \n",
      "2                                       0.0                            1.0   \n",
      "3                                       1.0                            0.0   \n",
      "4                                       1.0                            0.0   \n",
      "\n",
      "   iag_product_type_auto_Wheels  iag_region_ug_Consumer Claims Ops  \\\n",
      "0                           0.0                                0.0   \n",
      "1                           0.0                                1.0   \n",
      "2                           0.0                                1.0   \n",
      "3                           0.0                                0.0   \n",
      "4                           0.0                                1.0   \n",
      "\n",
      "   iag_region_ug_Retail Network Claims  target  \n",
      "0                                  0.0       2  \n",
      "1                                  0.0       1  \n",
      "2                                  0.0       2  \n",
      "3                                  1.0       2  \n",
      "4                                  0.0       2  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "\n",
      "Target variable distribution:\n",
      "0     463\n",
      "1    1774\n",
      "2    5662\n",
      "3     558\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Define features based on importance\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_site_ug',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Custom transformer for binning numeric features - using the same bins as before\n",
    "class NumericBinner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Using the same bins as in our previous analysis\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "        self.price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        # Apply binning to trust confidence - same as previous code\n",
    "        X_copy['iag_trust_confidence_scale11'] = pd.cut(\n",
    "            X_copy['iag_trust_confidence_scale11'],\n",
    "            bins=self.trust_bins,\n",
    "            labels=self.trust_labels\n",
    "        )\n",
    "        # Apply binning to price value - same as previous code\n",
    "        X_copy['iag_value_price_of_policy_reflects_scale11'] = pd.cut(\n",
    "            X_copy['iag_value_price_of_policy_reflects_scale11'],\n",
    "            bins=self.price_bins,\n",
    "            labels=self.price_labels\n",
    "        )\n",
    "        return X_copy\n",
    "\n",
    "# Create preprocessing steps\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('binner', NumericBinner()),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))  # Convert binned categories to dummy variables\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'))  # Convert categories to dummy variables\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# First, drop rows with missing values in key features\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Create label encoder for target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Fit and transform the features\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "# Get feature names after transformation\n",
    "def get_feature_names(pipeline, feature_names):\n",
    "    # Get names for binned numeric features\n",
    "    numeric_features_binned = []\n",
    "    for feature in numeric_features:\n",
    "        if feature == 'iag_trust_confidence_scale11':\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Low', 'Moderate', 'High', 'Very High']])  # Dropped 'Very Low' as reference\n",
    "        else:\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Fair', 'Good', 'Very Good', 'Excellent']])  # Dropped 'Poor' as reference\n",
    "    \n",
    "    # Get names for categorical features\n",
    "    categorical_features_encoded = []\n",
    "    for feature in categorical_features:\n",
    "        unique_values = sorted(df_clean[feature].unique())[1:]  # Exclude first category (reference level)\n",
    "        categorical_features_encoded.extend([f'{feature}_{val}' for val in unique_values])\n",
    "    \n",
    "    return numeric_features_binned + categorical_features_encoded\n",
    "\n",
    "feature_names = get_feature_names(pipeline, features_to_check)\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "\n",
    "# Add encoded target variable\n",
    "X_transformed_df['target'] = y_encoded\n",
    "\n",
    "# Display information about the transformed dataset\n",
    "print(\"Shape of transformed data:\", X_transformed_df.shape)\n",
    "print(\"\\nTarget variable encoding:\")\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "\n",
    "print(\"\\nFirst few rows of transformed data:\")\n",
    "print(X_transformed_df.head())\n",
    "\n",
    "# Display distribution of target variable\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(pd.Series(y_encoded).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pipeline executed before train-test split which is incorrect. Fixed in next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed data: (8457, 79)\n",
      "\n",
      "Target variable encoding:\n",
      "Detract: 0\n",
      "Passive: 1\n",
      "Promote: 2\n",
      "Super Detract: 3\n",
      "\n",
      "One-hot encoded version (first 5 rows):\n",
      "   iag_trust_confidence_scale11_Low  iag_trust_confidence_scale11_Moderate  \\\n",
      "0                               0.0                                    0.0   \n",
      "1                               0.0                                    1.0   \n",
      "2                               0.0                                    0.0   \n",
      "3                               0.0                                    0.0   \n",
      "4                               0.0                                    0.0   \n",
      "\n",
      "   iag_trust_confidence_scale11_High  iag_trust_confidence_scale11_Very High  \\\n",
      "0                                0.0                                     0.0   \n",
      "1                                0.0                                     0.0   \n",
      "2                                1.0                                     0.0   \n",
      "3                                1.0                                     0.0   \n",
      "4                                1.0                                     0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Fair  \\\n",
      "0                                              0.0   \n",
      "1                                              0.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Good  \\\n",
      "0                                              0.0   \n",
      "1                                              1.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Very Good  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Excellent  \\\n",
      "0                                                1.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_business_unit_ug_Operations  iag_age_band_auto_25-34  ...  \\\n",
      "0                              1.0                      0.0  ...   \n",
      "1                              1.0                      0.0  ...   \n",
      "2                              1.0                      0.0  ...   \n",
      "3                              0.0                      0.0  ...   \n",
      "4                              1.0                      0.0  ...   \n",
      "\n",
      "   iag_product_type_auto_Home Pack  iag_product_type_auto_Homeowners Line  \\\n",
      "0                              0.0                                    0.0   \n",
      "1                              1.0                                    0.0   \n",
      "2                              0.0                                    0.0   \n",
      "3                              0.0                                    0.0   \n",
      "4                              0.0                                    0.0   \n",
      "\n",
      "   iag_product_type_auto_Jetsetter  iag_product_type_auto_Landlord  \\\n",
      "0                              0.0                             0.0   \n",
      "1                              0.0                             0.0   \n",
      "2                              0.0                             0.0   \n",
      "3                              0.0                             0.0   \n",
      "4                              0.0                             0.0   \n",
      "\n",
      "   iag_product_type_auto_Private Motor Line  iag_product_type_auto_Vehicle  \\\n",
      "0                                       0.0                            1.0   \n",
      "1                                       0.0                            0.0   \n",
      "2                                       0.0                            1.0   \n",
      "3                                       1.0                            0.0   \n",
      "4                                       1.0                            0.0   \n",
      "\n",
      "   iag_product_type_auto_Wheels  iag_region_ug_Consumer Claims Ops  \\\n",
      "0                           0.0                                0.0   \n",
      "1                           0.0                                1.0   \n",
      "2                           0.0                                1.0   \n",
      "3                           0.0                                0.0   \n",
      "4                           0.0                                1.0   \n",
      "\n",
      "   iag_region_ug_Retail Network Claims  target  \n",
      "0                                  0.0       2  \n",
      "1                                  0.0       1  \n",
      "2                                  0.0       2  \n",
      "3                                  1.0       2  \n",
      "4                                  0.0       2  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "\n",
      "Readable version (first 5 rows):\n",
      "  iag_trust_confidence_scale11 iag_value_price_of_policy_reflects_scale11  \\\n",
      "0                    Low (ref)                                  Excellent   \n",
      "1                     Moderate                                       Good   \n",
      "2                         High                                 Fair (ref)   \n",
      "3                         High                                 Fair (ref)   \n",
      "4                         High                                 Fair (ref)   \n",
      "\n",
      "  iag_business_unit_ug iag_age_band_auto iag_tenure_band_enum  \\\n",
      "0           Operations             45-54                  3-5   \n",
      "1           Operations             55-64                21-30   \n",
      "2           Operations               65+                21-30   \n",
      "3     Operations (ref)             45-54                11-20   \n",
      "4           Operations             55-64                21-30   \n",
      "\n",
      "              iag_site_ug iag_product_type_auto              iag_region_ug  \\\n",
      "0  WNS Manila Philippines               Vehicle  Consumer Claims Ops (ref)   \n",
      "1  L3W 14 Show Place Chch             Home Pack        Consumer Claims Ops   \n",
      "2  L3W 14 Show Place Chch               Vehicle        Consumer Claims Ops   \n",
      "3           AMI Whanganui    Private Motor Line      Retail Network Claims   \n",
      "4               Albany L1    Private Motor Line        Consumer Claims Ops   \n",
      "\n",
      "  Likely_to_recommend  \n",
      "0             Promote  \n",
      "1             Passive  \n",
      "2             Promote  \n",
      "3             Promote  \n",
      "4             Promote  \n",
      "\n",
      "Target variable distribution:\n",
      "0     463\n",
      "1    1774\n",
      "2    5662\n",
      "3     558\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Define features based on importance\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_site_ug',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Custom transformer for binning numeric features\n",
    "class NumericBinner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "        self.price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['iag_trust_confidence_scale11'] = pd.cut(\n",
    "            X_copy['iag_trust_confidence_scale11'],\n",
    "            bins=self.trust_bins,\n",
    "            labels=self.trust_labels\n",
    "        )\n",
    "        X_copy['iag_value_price_of_policy_reflects_scale11'] = pd.cut(\n",
    "            X_copy['iag_value_price_of_policy_reflects_scale11'],\n",
    "            bins=self.price_bins,\n",
    "            labels=self.price_labels\n",
    "        )\n",
    "        return X_copy\n",
    "\n",
    "# Create preprocessing steps\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('binner', NumericBinner()),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Drop rows with missing values in key features\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Create label encoder for target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Fit and transform the features\n",
    "X_transformed = pipeline.fit_transform(X)\n",
    "\n",
    "# Get feature names after transformation\n",
    "def get_feature_names(pipeline, feature_names):\n",
    "    numeric_features_binned = []\n",
    "    for feature in numeric_features:\n",
    "        if feature == 'iag_trust_confidence_scale11':\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Low', 'Moderate', 'High', 'Very High']])\n",
    "        else:\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Fair', 'Good', 'Very Good', 'Excellent']])\n",
    "    \n",
    "    categorical_features_encoded = []\n",
    "    for feature in categorical_features:\n",
    "        unique_values = sorted(df_clean[feature].unique())[1:]\n",
    "        categorical_features_encoded.extend([f'{feature}_{val}' for val in unique_values])\n",
    "    \n",
    "    return numeric_features_binned + categorical_features_encoded\n",
    "\n",
    "feature_names = get_feature_names(pipeline, features_to_check)\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "\n",
    "# Add encoded target variable\n",
    "X_transformed_df['target'] = y_encoded\n",
    "\n",
    "# Display information about the transformed dataset\n",
    "print(\"Shape of transformed data:\", X_transformed_df.shape)\n",
    "print(\"\\nTarget variable encoding:\")\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "\n",
    "# Create a more readable version of the dataset\n",
    "readable_df = pd.DataFrame(index=range(len(X_transformed_df)))\n",
    "\n",
    "for feature in ['iag_trust_confidence_scale11', 'iag_value_price_of_policy_reflects_scale11',\n",
    "               'iag_business_unit_ug', 'iag_age_band_auto', 'iag_tenure_band_enum',\n",
    "               'iag_site_ug', 'iag_product_type_auto', 'iag_region_ug']:\n",
    "    relevant_cols = [col for col in X_transformed_df.columns if col.startswith(feature)]\n",
    "    categories = []\n",
    "    for idx in range(len(X_transformed_df)):\n",
    "        row_values = X_transformed_df.loc[idx, relevant_cols]\n",
    "        if row_values.max() == 0:  # If all are 0, it's the reference category\n",
    "            category = relevant_cols[0].split('_')[-1] + \" (ref)\"\n",
    "        else:\n",
    "            category = relevant_cols[row_values.argmax()].split('_')[-1]\n",
    "        categories.append(category)\n",
    "    readable_df[feature] = categories\n",
    "\n",
    "readable_df['Likely_to_recommend'] = le.inverse_transform(X_transformed_df['target'])\n",
    "\n",
    "# Display both versions of the transformed data\n",
    "print(\"\\nOne-hot encoded version (first 5 rows):\")\n",
    "print(X_transformed_df.head())\n",
    "\n",
    "print(\"\\nReadable version (first 5 rows):\")\n",
    "print(readable_df.head())\n",
    "\n",
    "# Display target distribution\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(pd.Series(y_encoded).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Pipeline\n",
    "\n",
    "This step prepares our data for modeling by implementing a structured preprocessing pipeline. The key steps are:\n",
    "\n",
    "## 1. Train-Test Split\n",
    "- Splitting data before preprocessing to prevent data leakage\n",
    "- 80-20 split with stratification to maintain target class distribution\n",
    "- Random state set for reproducibility\n",
    "\n",
    "## 2. Feature Processing\n",
    "### Numeric Features (Trust and Price Value):\n",
    "- Using previously validated binning strategy:\n",
    "  - Trust Confidence: 5 bins ('Very Low', 'Low', 'Moderate', 'High', 'Very High')\n",
    "  - Price Value: 5 bins ('Poor', 'Fair', 'Good', 'Very Good', 'Excellent')\n",
    "- One-hot encoding of binned categories\n",
    "\n",
    "### Categorical Features:\n",
    "- One-hot encoding for:\n",
    "  - Business Unit\n",
    "  - Age Band\n",
    "  - Tenure Band\n",
    "  - Site\n",
    "  - Product Type\n",
    "  - Region\n",
    "- First category dropped as reference to avoid multicollinearity\n",
    "\n",
    "## 3. Target Variable\n",
    "- Label encoded 'Likely to recommend':\n",
    "  - Detract: 0\n",
    "  - Passive: 1\n",
    "  - Promote: 2\n",
    "  - Super Detract: 3\n",
    "\n",
    "## Purpose\n",
    "- Create consistent, reproducible preprocessing workflow\n",
    "- Handle missing values by removing rows (low percentage of missingness)\n",
    "- Transform categorical variables appropriately for modeling\n",
    "- Maintain proper separation of training and testing data\n",
    "\n",
    "This pipeline ensures our data is properly prepared for subsequent modeling while preventing data leakage and maintaining interpretability of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (6765, 78)\n",
      "Testing set shape: (1692, 78)\n",
      "\n",
      "Target variable encoding:\n",
      "Detract: 0\n",
      "Passive: 1\n",
      "Promote: 2\n",
      "Super Detract: 3\n",
      "\n",
      "Training set target distribution:\n",
      "0     371\n",
      "1    1419\n",
      "2    4529\n",
      "3     446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing set target distribution:\n",
      "0      92\n",
      "1     355\n",
      "2    1133\n",
      "3     112\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few rows of transformed training data:\n",
      "   iag_trust_confidence_scale11_Low  iag_trust_confidence_scale11_Moderate  \\\n",
      "0                               0.0                                    1.0   \n",
      "1                               0.0                                    0.0   \n",
      "2                               0.0                                    0.0   \n",
      "3                               0.0                                    0.0   \n",
      "4                               0.0                                    0.0   \n",
      "\n",
      "   iag_trust_confidence_scale11_High  iag_trust_confidence_scale11_Very High  \\\n",
      "0                                0.0                                     0.0   \n",
      "1                                1.0                                     0.0   \n",
      "2                                1.0                                     0.0   \n",
      "3                                1.0                                     0.0   \n",
      "4                                0.0                                     0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Fair  \\\n",
      "0                                              0.0   \n",
      "1                                              0.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Good  \\\n",
      "0                                              1.0   \n",
      "1                                              0.0   \n",
      "2                                              0.0   \n",
      "3                                              0.0   \n",
      "4                                              0.0   \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Very Good  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_value_price_of_policy_reflects_scale11_Excellent  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                1.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   iag_business_unit_ug_Operations  iag_age_band_auto_25-34  ...  \\\n",
      "0                              1.0                      0.0  ...   \n",
      "1                              1.0                      0.0  ...   \n",
      "2                              1.0                      0.0  ...   \n",
      "3                              1.0                      0.0  ...   \n",
      "4                              1.0                      0.0  ...   \n",
      "\n",
      "   iag_product_type_auto_Home Pack  iag_product_type_auto_Homeowners Line  \\\n",
      "0                              0.0                                    0.0   \n",
      "1                              0.0                                    0.0   \n",
      "2                              0.0                                    0.0   \n",
      "3                              0.0                                    1.0   \n",
      "4                              0.0                                    1.0   \n",
      "\n",
      "   iag_product_type_auto_Jetsetter  iag_product_type_auto_Landlord  \\\n",
      "0                              0.0                             0.0   \n",
      "1                              0.0                             0.0   \n",
      "2                              0.0                             0.0   \n",
      "3                              0.0                             0.0   \n",
      "4                              0.0                             0.0   \n",
      "\n",
      "   iag_product_type_auto_Private Motor Line  iag_product_type_auto_Vehicle  \\\n",
      "0                                       1.0                            0.0   \n",
      "1                                       1.0                            0.0   \n",
      "2                                       0.0                            1.0   \n",
      "3                                       0.0                            0.0   \n",
      "4                                       0.0                            0.0   \n",
      "\n",
      "   iag_product_type_auto_Wheels  iag_region_ug_Consumer Claims Ops  \\\n",
      "0                           0.0                                1.0   \n",
      "1                           0.0                                1.0   \n",
      "2                           0.0                                1.0   \n",
      "3                           0.0                                0.0   \n",
      "4                           0.0                                0.0   \n",
      "\n",
      "   iag_region_ug_Retail Network Claims  target  \n",
      "0                                  0.0       1  \n",
      "1                                  0.0       1  \n",
      "2                                  0.0       2  \n",
      "3                                  1.0       2  \n",
      "4                                  0.0       2  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fixed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Define features based on importance\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_site_ug',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in key features\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check)\n",
    "\n",
    "# Prepare X and y before train test split\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Custom transformer for binning numeric features\n",
    "class NumericBinner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "        self.price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['iag_trust_confidence_scale11'] = pd.cut(\n",
    "            X_copy['iag_trust_confidence_scale11'],\n",
    "            bins=self.trust_bins,\n",
    "            labels=self.trust_labels\n",
    "        )\n",
    "        X_copy['iag_value_price_of_policy_reflects_scale11'] = pd.cut(\n",
    "            X_copy['iag_value_price_of_policy_reflects_scale11'],\n",
    "            bins=self.price_bins,\n",
    "            labels=self.price_labels\n",
    "        )\n",
    "        return X_copy\n",
    "\n",
    "# Create preprocessing steps\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('binner', NumericBinner()),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Create label encoder for target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Fit pipeline on training data and transform both train and test\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "# Get feature names after transformation\n",
    "def get_feature_names(pipeline, feature_names):\n",
    "    numeric_features_binned = []\n",
    "    for feature in numeric_features:\n",
    "        if feature == 'iag_trust_confidence_scale11':\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Low', 'Moderate', 'High', 'Very High']])\n",
    "        else:\n",
    "            numeric_features_binned.extend([f'{feature}_{label}' for label in \n",
    "                                          ['Fair', 'Good', 'Very Good', 'Excellent']])\n",
    "    \n",
    "    categorical_features_encoded = []\n",
    "    for feature in categorical_features:\n",
    "        unique_values = sorted(X_train[feature].unique())[1:]\n",
    "        categorical_features_encoded.extend([f'{feature}_{val}' for val in unique_values])\n",
    "    \n",
    "    return numeric_features_binned + categorical_features_encoded\n",
    "\n",
    "feature_names = get_feature_names(pipeline, features_to_check)\n",
    "\n",
    "# Convert transformed data to DataFrames\n",
    "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "X_test_transformed_df = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "\n",
    "# Add encoded target variables\n",
    "X_train_transformed_df['target'] = y_train_encoded\n",
    "X_test_transformed_df['target'] = y_test_encoded\n",
    "\n",
    "# Print information about the splits\n",
    "print(\"Training set shape:\", X_train_transformed_df.shape)\n",
    "print(\"Testing set shape:\", X_test_transformed_df.shape)\n",
    "\n",
    "print(\"\\nTarget variable encoding:\")\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "\n",
    "print(\"\\nTraining set target distribution:\")\n",
    "print(pd.Series(y_train_encoded).value_counts().sort_index())\n",
    "print(\"\\nTesting set target distribution:\")\n",
    "print(pd.Series(y_test_encoded).value_counts().sort_index())\n",
    "\n",
    "# Display first few rows of transformed training data\n",
    "print(\"\\nFirst few rows of transformed training data:\")\n",
    "print(X_train_transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types before preprocessing:\n",
      "iag_trust_confidence_scale11                  float64\n",
      "iag_value_price_of_policy_reflects_scale11    float64\n",
      "iag_business_unit_ug                           object\n",
      "iag_age_band_auto                              object\n",
      "iag_tenure_band_enum                           object\n",
      "iag_product_type_auto                          object\n",
      "iag_region_ug                                  object\n",
      "dtype: object\n",
      "\n",
      "Encoded categories for target:\n",
      "Detract: 0\n",
      "Passive: 1\n",
      "Promote: 2\n",
      "Super Detract: 3\n",
      "\n",
      "Data types after preprocessing:\n",
      "const                                         float64\n",
      "iag_business_unit_ug_encoded                    int32\n",
      "iag_age_band_auto_encoded                       int32\n",
      "iag_tenure_band_enum_encoded                    int32\n",
      "iag_product_type_auto_encoded                   int32\n",
      "iag_region_ug_encoded                           int32\n",
      "iag_trust_confidence_scale11                  float64\n",
      "iag_value_price_of_policy_reflects_scale11    float64\n",
      "dtype: object\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602821\n",
      "         Iterations 8\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:         target_encoded   No. Observations:                 6765\n",
      "Model:                        MNLogit   Df Residuals:                     6741\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Sun, 19 Jan 2025   Pseudo R-squ.:                  0.3551\n",
      "Time:                        22:37:53   Log-Likelihood:                -4078.1\n",
      "converged:                       True   LL-Null:                       -6323.4\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================================================\n",
      "                          target_encoded=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "const                                         -1.8989      0.472     -4.027      0.000      -2.823      -0.975\n",
      "iag_business_unit_ug_encoded                  -0.2193      0.284     -0.773      0.439      -0.775       0.336\n",
      "iag_age_band_auto_encoded                      0.1029      0.045      2.273      0.023       0.014       0.192\n",
      "iag_tenure_band_enum_encoded                   0.0144      0.036      0.394      0.693      -0.057       0.086\n",
      "iag_product_type_auto_encoded                 -0.0138      0.034     -0.409      0.683      -0.080       0.052\n",
      "iag_region_ug_encoded                          0.1944      0.106      1.835      0.066      -0.013       0.402\n",
      "iag_trust_confidence_scale11                   0.3751      0.036     10.421      0.000       0.305       0.446\n",
      "iag_value_price_of_policy_reflects_scale11     0.0473      0.036      1.329      0.184      -0.022       0.117\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "                          target_encoded=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "const                                         -9.0706      0.529    -17.156      0.000     -10.107      -8.034\n",
      "iag_business_unit_ug_encoded                  -0.1977      0.289     -0.684      0.494      -0.764       0.369\n",
      "iag_age_band_auto_encoded                      0.0677      0.046      1.471      0.141      -0.022       0.158\n",
      "iag_tenure_band_enum_encoded                   0.0405      0.037      1.091      0.275      -0.032       0.113\n",
      "iag_product_type_auto_encoded                 -0.0478      0.035     -1.375      0.169      -0.116       0.020\n",
      "iag_region_ug_encoded                          0.3062      0.109      2.801      0.005       0.092       0.520\n",
      "iag_trust_confidence_scale11                   1.0750      0.044     24.364      0.000       0.989       1.162\n",
      "iag_value_price_of_policy_reflects_scale11     0.3467      0.039      8.966      0.000       0.271       0.423\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "                          target_encoded=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "const                                          2.6673      0.614      4.343      0.000       1.464       3.871\n",
      "iag_business_unit_ug_encoded                  -0.1903      0.408     -0.466      0.641      -0.990       0.610\n",
      "iag_age_band_auto_encoded                     -0.0674      0.064     -1.050      0.294      -0.193       0.058\n",
      "iag_tenure_band_enum_encoded                   0.0198      0.051      0.387      0.699      -0.080       0.120\n",
      "iag_product_type_auto_encoded                  0.1260      0.049      2.588      0.010       0.031       0.221\n",
      "iag_region_ug_encoded                          0.0637      0.149      0.426      0.670      -0.229       0.357\n",
      "iag_trust_confidence_scale11                  -0.4418      0.041    -10.678      0.000      -0.523      -0.361\n",
      "iag_value_price_of_policy_reflects_scale11    -0.2047      0.042     -4.854      0.000      -0.287      -0.122\n",
      "==============================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_23284\\2690719318.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['target_encoded'] = target_encoder.fit_transform(df_clean['Likely to recommend'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Define features\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check)\n",
    "\n",
    "# First, let's examine our data types\n",
    "print(\"Data types before preprocessing:\")\n",
    "print(df_clean[features_to_check].dtypes)\n",
    "\n",
    "# Create label encoders for categorical variables\n",
    "encoders = {}\n",
    "for cat_feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[f\"{cat_feature}_encoded\"] = le.fit_transform(df_clean[cat_feature])\n",
    "    encoders[cat_feature] = le\n",
    "\n",
    "# Create label encoder for target variable\n",
    "target_encoder = LabelEncoder()\n",
    "df_clean['target_encoded'] = target_encoder.fit_transform(df_clean['Likely to recommend'])\n",
    "\n",
    "# Print encoded categories for reference\n",
    "print(\"\\nEncoded categories for target:\")\n",
    "for i, category in enumerate(target_encoder.classes_):\n",
    "    print(f\"{category}: {i}\")\n",
    "\n",
    "# Prepare features for modeling\n",
    "X_columns = [f\"{col}_encoded\" for col in categorical_features] + numeric_features\n",
    "X = df_clean[X_columns].copy()\n",
    "y = df_clean['target_encoded']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Add constant\n",
    "X_train_with_const = sm.add_constant(X_train)\n",
    "X_test_with_const = sm.add_constant(X_test)\n",
    "\n",
    "# Print final data types\n",
    "print(\"\\nData types after preprocessing:\")\n",
    "print(X_train_with_const.dtypes)\n",
    "\n",
    "# Now try to fit the model\n",
    "model = sm.MNLogit(y_train, X_train_with_const)\n",
    "result = model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        92\n",
      "           1       0.52      0.40      0.45       355\n",
      "           2       0.82      0.94      0.88      1133\n",
      "           3       0.76      0.78      0.77       112\n",
      "\n",
      "    accuracy                           0.77      1692\n",
      "   macro avg       0.53      0.53      0.52      1692\n",
      "weighted avg       0.71      0.77      0.73      1692\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = result.predict(X_test_with_const)\n",
    "predicted_classes = predictions.idxmax(axis=1)\n",
    "\n",
    "# Calculate and print classification metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Detract', 'Passive', 'Promote', 'Super Detract'],\n",
    "            yticklabels=['Detract', 'Passive', 'Promote', 'Super Detract'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Starting data preparation...\n",
      "\n",
      "Found 2 highly correlated pairs\n",
      "Sample correlated pairs:\n",
      "iag_trust_confidence_scale11 -- iag_value_price_of_policy_reflects_scale11: 0.780\n",
      "iag_product_type_auto_Homeowners Line -- iag_product_type_auto_Private Motor Line: 0.723\n",
      "\n",
      "Removed 2 collinear features\n",
      "\n",
      "Final feature matrix shape: (8457, 24)\n",
      "Feature matrix dtype: float64\n",
      "Target vector dtype: int64\n",
      "\n",
      "Trying newton optimization...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407849\n",
      "         Iterations 525\n",
      "newton optimization failed: Singular matrix\n",
      "\n",
      "Trying bfgs optimization...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407851\n",
      "         Iterations: 211\n",
      "         Function evaluations: 212\n",
      "         Gradient evaluations: 212\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "Significant Features (p < 0.05):\n",
      "                              Feature  Coefficient       P_Value  Odds_Ratio\n",
      "1        iag_trust_confidence_scale11     2.370548  0.000000e+00   10.703252\n",
      "22  iag_region_ug_Consumer Claims Ops     0.370696  4.546091e-07    1.448743\n",
      "0                               const     0.963058  3.912747e-04    2.619695\n",
      "20      iag_product_type_auto_Vehicle    -0.325141  2.087533e-03    0.722425\n",
      "21       iag_product_type_auto_Wheels    -0.862629  8.852860e-03    0.422051\n",
      "16    iag_product_type_auto_Home Pack    -0.478929  3.070000e-02    0.619447\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.812\n",
      "ROC AUC: 0.878\n",
      "McFadden's Pseudo R-squared: 0.357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.798808  0.575313  0.668885  2795.000000\n",
      "1              0.815798  0.928471  0.868495  5662.000000\n",
      "accuracy       0.811754  0.811754  0.811754     0.811754\n",
      "macro avg      0.807303  0.751892  0.768690  8457.000000\n",
      "weighted avg   0.810183  0.811754  0.802525  8457.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "class RecommendationAnalysis:\n",
    "    def __init__(self):\n",
    "        self.numeric_features = [\n",
    "            'iag_trust_confidence_scale11',\n",
    "            'iag_value_price_of_policy_reflects_scale11'\n",
    "        ]\n",
    "        self.categorical_features = [\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "        self.selected_features = None  # Store selected features\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        print(\"\\nStarting data preparation...\")\n",
    "        \n",
    "        # Drop missing values\n",
    "        features = self.numeric_features + self.categorical_features\n",
    "        df_clean = df.dropna(subset=features + ['Likely to recommend']).copy()\n",
    "        \n",
    "        # Scale numeric features\n",
    "        scaler = StandardScaler()\n",
    "        df_clean[self.numeric_features] = scaler.fit_transform(df_clean[self.numeric_features])\n",
    "        \n",
    "        # Create dummy variables\n",
    "        X_categorical = pd.get_dummies(df_clean[self.categorical_features], \n",
    "                                     drop_first=True, \n",
    "                                     dummy_na=False)\n",
    "        \n",
    "        # Combine features\n",
    "        X = pd.concat([df_clean[self.numeric_features], X_categorical], axis=1)\n",
    "        \n",
    "        # Ensure all features are float64\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Add constant\n",
    "        X = sm.add_constant(X)\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Convert target to binary (Promote vs Others)\n",
    "        y = (df_clean['Likely to recommend'] == 'Promote').astype(np.int64)\n",
    "        \n",
    "        return X, y, df_clean\n",
    "    \n",
    "    def check_collinearity(self, X):\n",
    "        \"\"\"Check and handle collinearity\"\"\"\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = X.corr().abs()\n",
    "        \n",
    "        # Find highly correlated pairs\n",
    "        high_corr_pairs = []\n",
    "        cols_to_drop = set()\n",
    "        \n",
    "        for i, col1 in enumerate(corr_matrix.columns):\n",
    "            for j, col2 in enumerate(corr_matrix.columns[i+1:], i+1):\n",
    "                if corr_matrix.iloc[i, j] > 0.7 and col1 != 'const':\n",
    "                    high_corr_pairs.append((col1, col2, corr_matrix.iloc[i, j]))\n",
    "                    cols_to_drop.add(col2)  # Drop the second of each pair\n",
    "        \n",
    "        print(f\"\\nFound {len(high_corr_pairs)} highly correlated pairs\")\n",
    "        if high_corr_pairs:\n",
    "            print(\"Sample correlated pairs:\")\n",
    "            for col1, col2, corr in high_corr_pairs[:5]:\n",
    "                print(f\"{col1} -- {col2}: {corr:.3f}\")\n",
    "        \n",
    "        return list(cols_to_drop)\n",
    "    \n",
    "    def fit_model(self, X, y):\n",
    "        try:\n",
    "            # Remove highly correlated features\n",
    "            cols_to_drop = self.check_collinearity(X)\n",
    "            if cols_to_drop:\n",
    "                X = X.drop(columns=cols_to_drop)\n",
    "                print(f\"\\nRemoved {len(cols_to_drop)} collinear features\")\n",
    "            \n",
    "            # Store selected features for prediction\n",
    "            self.selected_features = X.columns\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "            y_np = y.to_numpy(dtype=np.int64)\n",
    "            \n",
    "            print(f\"\\nFinal feature matrix shape: {X_np.shape}\")\n",
    "            print(f\"Feature matrix dtype: {X_np.dtype}\")\n",
    "            print(f\"Target vector dtype: {y_np.dtype}\")\n",
    "            \n",
    "            # Try different optimization methods\n",
    "            methods = ['newton', 'bfgs', 'lbfgs']\n",
    "            for method in methods:\n",
    "                try:\n",
    "                    print(f\"\\nTrying {method} optimization...\")\n",
    "                    model = sm.Logit(y_np, X_np)\n",
    "                    results = model.fit(method=method, maxiter=1000)\n",
    "                    \n",
    "                    if hasattr(results, 'mle_retvals') and \\\n",
    "                       'converged' in results.mle_retvals and \\\n",
    "                       not results.mle_retvals['converged']:\n",
    "                        print(f\"{method} did not converge, trying next method...\")\n",
    "                        continue\n",
    "                    \n",
    "                    return results\n",
    "                except Exception as e:\n",
    "                    print(f\"{method} optimization failed: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            raise Exception(\"All optimization methods failed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Model fitting failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze(self, df):\n",
    "        X, y, df_clean = self.prepare_data(df)\n",
    "        results = self.fit_model(X, y)\n",
    "        \n",
    "        if results is not None and self.selected_features is not None:\n",
    "            # Create summary DataFrame\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Feature': self.selected_features,\n",
    "                'Coefficient': results.params,\n",
    "                'P_Value': results.pvalues,\n",
    "                'Odds_Ratio': np.exp(results.params)\n",
    "            })\n",
    "            summary_df = summary_df.sort_values('P_Value')\n",
    "            \n",
    "            # Calculate predictions using only selected features\n",
    "            X_pred = X[self.selected_features]\n",
    "            X_np = X_pred.to_numpy(dtype=np.float64)\n",
    "            y_pred = results.predict(X_np)\n",
    "            y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': (y_pred_binary == y).mean(),\n",
    "                'roc_auc': roc_auc_score(y, y_pred),\n",
    "                'classification_report': classification_report(y, y_pred_binary, output_dict=True),\n",
    "                'pseudo_r2': results.prsquared\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'feature_importance': summary_df,\n",
    "                'metrics': metrics,\n",
    "                'model': results\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Run analysis\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "analyzer = RecommendationAnalysis()\n",
    "results = analyzer.analyze(df)\n",
    "\n",
    "if results:\n",
    "    print(\"\\nModel Summary:\")\n",
    "    \n",
    "    print(\"\\nSignificant Features (p < 0.05):\")\n",
    "    significant_features = results['feature_importance'][results['feature_importance']['P_Value'] < 0.05]\n",
    "    print(significant_features[['Feature', 'Coefficient', 'P_Value', 'Odds_Ratio']])\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    metrics = results['metrics']\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print(f\"McFadden's Pseudo R-squared: {metrics['pseudo_r2']:.3f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    cls_report = pd.DataFrame(metrics['classification_report']).transpose()\n",
    "    print(cls_report)\n",
    "else:\n",
    "    print(\"Model fitting failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Starting data preparation...\n",
      "\n",
      "Created dummy variables:\n",
      "- iag_business_unit_ug_Operations\n",
      "- iag_age_band_auto_25-34\n",
      "- iag_age_band_auto_35-44\n",
      "- iag_age_band_auto_45-54\n",
      "- iag_age_band_auto_55-64\n",
      "- iag_age_band_auto_65+\n",
      "- iag_tenure_band_enum_11-20\n",
      "- iag_tenure_band_enum_21-30\n",
      "- iag_tenure_band_enum_3-5\n",
      "- iag_tenure_band_enum_30+\n",
      "- iag_tenure_band_enum_6-10\n",
      "- iag_tenure_band_enum_<1\n",
      "- iag_product_type_auto_EasyRider\n",
      "- iag_product_type_auto_Home\n",
      "- iag_product_type_auto_Home Pack\n",
      "- iag_product_type_auto_Homeowners Line\n",
      "- iag_product_type_auto_Jetsetter\n",
      "- iag_product_type_auto_Landlord\n",
      "- iag_product_type_auto_Private Motor Line\n",
      "- iag_product_type_auto_Vehicle\n",
      "- iag_product_type_auto_Wheels\n",
      "- iag_region_ug_Consumer Claims Ops\n",
      "- iag_region_ug_Retail Network Claims\n",
      "\n",
      "All features after combining numeric and categorical:\n",
      "- iag_trust_confidence_scale11\n",
      "- iag_value_price_of_policy_reflects_scale11\n",
      "- iag_business_unit_ug_Operations\n",
      "- iag_age_band_auto_25-34\n",
      "- iag_age_band_auto_35-44\n",
      "- iag_age_band_auto_45-54\n",
      "- iag_age_band_auto_55-64\n",
      "- iag_age_band_auto_65+\n",
      "- iag_tenure_band_enum_11-20\n",
      "- iag_tenure_band_enum_21-30\n",
      "- iag_tenure_band_enum_3-5\n",
      "- iag_tenure_band_enum_30+\n",
      "- iag_tenure_band_enum_6-10\n",
      "- iag_tenure_band_enum_<1\n",
      "- iag_product_type_auto_EasyRider\n",
      "- iag_product_type_auto_Home\n",
      "- iag_product_type_auto_Home Pack\n",
      "- iag_product_type_auto_Homeowners Line\n",
      "- iag_product_type_auto_Jetsetter\n",
      "- iag_product_type_auto_Landlord\n",
      "- iag_product_type_auto_Private Motor Line\n",
      "- iag_product_type_auto_Vehicle\n",
      "- iag_product_type_auto_Wheels\n",
      "- iag_region_ug_Consumer Claims Ops\n",
      "- iag_region_ug_Retail Network Claims\n",
      "\n",
      "Found 2 highly correlated pairs:\n",
      "- iag_trust_confidence_scale11 -- iag_value_price_of_policy_reflects_scale11: 0.780\n",
      "- iag_product_type_auto_Homeowners Line -- iag_product_type_auto_Private Motor Line: 0.723\n",
      "\n",
      "Features to be dropped due to collinearity:\n",
      "- iag_value_price_of_policy_reflects_scale11\n",
      "- iag_product_type_auto_Private Motor Line\n",
      "\n",
      "Remaining features after removing collinearity:\n",
      "- const\n",
      "- iag_trust_confidence_scale11\n",
      "- iag_business_unit_ug_Operations\n",
      "- iag_age_band_auto_25-34\n",
      "- iag_age_band_auto_35-44\n",
      "- iag_age_band_auto_45-54\n",
      "- iag_age_band_auto_55-64\n",
      "- iag_age_band_auto_65+\n",
      "- iag_tenure_band_enum_11-20\n",
      "- iag_tenure_band_enum_21-30\n",
      "- iag_tenure_band_enum_3-5\n",
      "- iag_tenure_band_enum_30+\n",
      "- iag_tenure_band_enum_6-10\n",
      "- iag_tenure_band_enum_<1\n",
      "- iag_product_type_auto_EasyRider\n",
      "- iag_product_type_auto_Home\n",
      "- iag_product_type_auto_Home Pack\n",
      "- iag_product_type_auto_Homeowners Line\n",
      "- iag_product_type_auto_Jetsetter\n",
      "- iag_product_type_auto_Landlord\n",
      "- iag_product_type_auto_Vehicle\n",
      "- iag_product_type_auto_Wheels\n",
      "- iag_region_ug_Consumer Claims Ops\n",
      "- iag_region_ug_Retail Network Claims\n",
      "\n",
      "Final feature matrix shape: (8457, 24)\n",
      "\n",
      "Trying newton optimization...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407849\n",
      "         Iterations 525\n",
      "newton optimization failed: Singular matrix\n",
      "\n",
      "Trying bfgs optimization...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407851\n",
      "         Iterations: 211\n",
      "         Function evaluations: 212\n",
      "         Gradient evaluations: 212\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "All Features and their Coefficients:\n",
      "                                  Feature  Coefficient       P_Value  \\\n",
      "1            iag_trust_confidence_scale11     2.370548  0.000000e+00   \n",
      "22      iag_region_ug_Consumer Claims Ops     0.370696  4.546091e-07   \n",
      "0                                   const     0.963058  3.912747e-04   \n",
      "20          iag_product_type_auto_Vehicle    -0.325141  2.087533e-03   \n",
      "21           iag_product_type_auto_Wheels    -0.862629  8.852860e-03   \n",
      "16        iag_product_type_auto_Home Pack    -0.478929  3.070000e-02   \n",
      "2         iag_business_unit_ug_Operations    -0.271075  5.653910e-02   \n",
      "8              iag_tenure_band_enum_11-20    -0.227205  5.797339e-02   \n",
      "9              iag_tenure_band_enum_21-30    -0.243557  6.259946e-02   \n",
      "23    iag_region_ug_Retail Network Claims     0.185067  1.052312e-01   \n",
      "15             iag_product_type_auto_Home    -0.374081  2.707448e-01   \n",
      "17  iag_product_type_auto_Homeowners Line     0.074296  2.864525e-01   \n",
      "7                   iag_age_band_auto_65+    -0.168559  4.637399e-01   \n",
      "12              iag_tenure_band_enum_6-10    -0.097076  4.707967e-01   \n",
      "3                 iag_age_band_auto_25-34    -0.166021  4.772611e-01   \n",
      "19         iag_product_type_auto_Landlord    -0.853007  5.602262e-01   \n",
      "5                 iag_age_band_auto_45-54    -0.118363  6.076981e-01   \n",
      "11               iag_tenure_band_enum_30+     0.122738  6.471312e-01   \n",
      "6                 iag_age_band_auto_55-64    -0.065442  7.760696e-01   \n",
      "14        iag_product_type_auto_EasyRider    -4.034986  8.053534e-01   \n",
      "18        iag_product_type_auto_Jetsetter     1.956917  8.420622e-01   \n",
      "4                 iag_age_band_auto_35-44    -0.041065  8.621548e-01   \n",
      "10               iag_tenure_band_enum_3-5     0.018788  8.940534e-01   \n",
      "13                iag_tenure_band_enum_<1    -0.001212  9.941154e-01   \n",
      "\n",
      "    Odds_Ratio  \n",
      "1    10.703252  \n",
      "22    1.448743  \n",
      "0     2.619695  \n",
      "20    0.722425  \n",
      "21    0.422051  \n",
      "16    0.619447  \n",
      "2     0.762559  \n",
      "8     0.796758  \n",
      "9     0.783835  \n",
      "23    1.203299  \n",
      "15    0.687921  \n",
      "17    1.077125  \n",
      "7     0.844881  \n",
      "12    0.907487  \n",
      "3     0.847029  \n",
      "19    0.426132  \n",
      "5     0.888374  \n",
      "11    1.130589  \n",
      "6     0.936653  \n",
      "14    0.017686  \n",
      "18    7.077476  \n",
      "4     0.959766  \n",
      "10    1.018966  \n",
      "13    0.998788  \n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.812\n",
      "ROC AUC: 0.878\n",
      "McFadden's Pseudo R-squared: 0.357\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.798808  0.575313  0.668885  2795.000000\n",
      "1              0.815798  0.928471  0.868495  5662.000000\n",
      "accuracy       0.811754  0.811754  0.811754     0.811754\n",
      "macro avg      0.807303  0.751892  0.768690  8457.000000\n",
      "weighted avg   0.810183  0.811754  0.802525  8457.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "class RecommendationAnalysis:\n",
    "    def __init__(self):\n",
    "        self.numeric_features = [\n",
    "            'iag_trust_confidence_scale11',\n",
    "            'iag_value_price_of_policy_reflects_scale11'\n",
    "        ]\n",
    "        self.categorical_features = [\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        print(\"\\nStarting data preparation...\")\n",
    "        \n",
    "        # Drop missing values\n",
    "        features = self.numeric_features + self.categorical_features\n",
    "        df_clean = df.dropna(subset=features + ['Likely to recommend']).copy()\n",
    "        \n",
    "        # Scale numeric features\n",
    "        scaler = StandardScaler()\n",
    "        df_clean[self.numeric_features] = scaler.fit_transform(df_clean[self.numeric_features])\n",
    "        \n",
    "        # Create dummy variables\n",
    "        X_categorical = pd.get_dummies(df_clean[self.categorical_features], \n",
    "                                     drop_first=True, \n",
    "                                     dummy_na=False)\n",
    "        \n",
    "        print(\"\\nCreated dummy variables:\")\n",
    "        for col in X_categorical.columns:\n",
    "            print(f\"- {col}\")\n",
    "        \n",
    "        # Combine features\n",
    "        X = pd.concat([df_clean[self.numeric_features], X_categorical], axis=1)\n",
    "        print(\"\\nAll features after combining numeric and categorical:\")\n",
    "        for col in X.columns:\n",
    "            print(f\"- {col}\")\n",
    "        \n",
    "        # Ensure all features are float64\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Add constant\n",
    "        X = sm.add_constant(X)\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Convert target to binary (Promote vs Others)\n",
    "        y = (df_clean['Likely to recommend'] == 'Promote').astype(np.int64)\n",
    "        \n",
    "        return X, y, df_clean\n",
    "    \n",
    "    def check_collinearity(self, X):\n",
    "        \"\"\"Check and handle collinearity\"\"\"\n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = X.corr().abs()\n",
    "        \n",
    "        # Find highly correlated pairs\n",
    "        high_corr_pairs = []\n",
    "        cols_to_drop = set()\n",
    "        \n",
    "        for i, col1 in enumerate(corr_matrix.columns):\n",
    "            for j, col2 in enumerate(corr_matrix.columns[i+1:], i+1):\n",
    "                if corr_matrix.iloc[i, j] > 0.7 and col1 != 'const':\n",
    "                    high_corr_pairs.append((col1, col2, corr_matrix.iloc[i, j]))\n",
    "                    cols_to_drop.add(col2)  # Drop the second of each pair\n",
    "        \n",
    "        print(f\"\\nFound {len(high_corr_pairs)} highly correlated pairs:\")\n",
    "        for col1, col2, corr in high_corr_pairs:\n",
    "            print(f\"- {col1} -- {col2}: {corr:.3f}\")\n",
    "        \n",
    "        print(\"\\nFeatures to be dropped due to collinearity:\")\n",
    "        for col in cols_to_drop:\n",
    "            print(f\"- {col}\")\n",
    "        \n",
    "        return list(cols_to_drop)\n",
    "    \n",
    "    def fit_model(self, X, y):\n",
    "        try:\n",
    "            # Remove highly correlated features\n",
    "            cols_to_drop = self.check_collinearity(X)\n",
    "            if cols_to_drop:\n",
    "                X = X.drop(columns=cols_to_drop)\n",
    "                print(f\"\\nRemaining features after removing collinearity:\")\n",
    "                for col in X.columns:\n",
    "                    print(f\"- {col}\")\n",
    "            \n",
    "            # Store selected features for prediction\n",
    "            self.selected_features = X.columns\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "            y_np = y.to_numpy(dtype=np.int64)\n",
    "            \n",
    "            print(f\"\\nFinal feature matrix shape: {X_np.shape}\")\n",
    "            \n",
    "            # Try different optimization methods\n",
    "            methods = ['newton', 'bfgs', 'lbfgs']\n",
    "            for method in methods:\n",
    "                try:\n",
    "                    print(f\"\\nTrying {method} optimization...\")\n",
    "                    model = sm.Logit(y_np, X_np)\n",
    "                    results = model.fit(method=method, maxiter=1000)\n",
    "                    \n",
    "                    if hasattr(results, 'mle_retvals') and \\\n",
    "                       'converged' in results.mle_retvals and \\\n",
    "                       not results.mle_retvals['converged']:\n",
    "                        print(f\"{method} did not converge, trying next method...\")\n",
    "                        continue\n",
    "                    \n",
    "                    return results\n",
    "                except Exception as e:\n",
    "                    print(f\"{method} optimization failed: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            raise Exception(\"All optimization methods failed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Model fitting failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def analyze(self, df):\n",
    "        X, y, df_clean = self.prepare_data(df)\n",
    "        results = self.fit_model(X, y)\n",
    "        \n",
    "        if results is not None and self.selected_features is not None:\n",
    "            # Create summary DataFrame with all coefficients\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Feature': self.selected_features,\n",
    "                'Coefficient': results.params,\n",
    "                'P_Value': results.pvalues,\n",
    "                'Odds_Ratio': np.exp(results.params)\n",
    "            })\n",
    "            summary_df = summary_df.sort_values('P_Value')\n",
    "            \n",
    "            # Calculate predictions using only selected features\n",
    "            X_pred = X[self.selected_features]\n",
    "            X_np = X_pred.to_numpy(dtype=np.float64)\n",
    "            y_pred = results.predict(X_np)\n",
    "            y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': (y_pred_binary == y).mean(),\n",
    "                'roc_auc': roc_auc_score(y, y_pred),\n",
    "                'classification_report': classification_report(y, y_pred_binary, output_dict=True),\n",
    "                'pseudo_r2': results.prsquared\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'feature_importance': summary_df,\n",
    "                'metrics': metrics,\n",
    "                'model': results\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Run analysis\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "analyzer = RecommendationAnalysis()\n",
    "results = analyzer.analyze(df)\n",
    "\n",
    "if results:\n",
    "    print(\"\\nModel Summary:\")\n",
    "    \n",
    "    print(\"\\nAll Features and their Coefficients:\")\n",
    "    feature_importance = results['feature_importance']\n",
    "    print(feature_importance[['Feature', 'Coefficient', 'P_Value', 'Odds_Ratio']])\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    metrics = results['metrics']\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print(f\"McFadden's Pseudo R-squared: {metrics['pseudo_r2']:.3f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    cls_report = pd.DataFrame(metrics['classification_report']).transpose()\n",
    "    print(cls_report)\n",
    "else:\n",
    "    print(\"Model fitting failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Original data shape: (9264, 48)\n",
      "\n",
      "Column types:\n",
      "iag_trust_confidence_scale11                  float64\n",
      "iag_value_price_of_policy_reflects_scale11    float64\n",
      "Likely to recommend                            object\n",
      "dtype: object\n",
      "\n",
      "Starting data preparation...\n",
      "\n",
      "Shape after dropping missing values: (8457, 48)\n",
      "\n",
      "Unique values in binned features:\n",
      "Trust bins: iag_trust_confidence_binned\n",
      "Very High    3645\n",
      "High         1551\n",
      "Moderate     1435\n",
      "Low           972\n",
      "Very Low      854\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Price bins: iag_value_price_binned\n",
      "Excellent    4065\n",
      "Very Good    1639\n",
      "Poor         1154\n",
      "Good         1040\n",
      "Fair          559\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dummy variables created: 31\n",
      "Sample column names: ['iag_trust_confidence_binned_Low', 'iag_trust_confidence_binned_Moderate', 'iag_trust_confidence_binned_High', 'iag_trust_confidence_binned_Very High', 'iag_value_price_binned_Fair']\n",
      "\n",
      "Feature matrix shape: (8457, 32)\n",
      "Feature matrix dtype: [dtype('float64')]\n",
      "Target vector shape: (8457,)\n",
      "Target distribution:\n",
      " Likely to recommend\n",
      "1    5662\n",
      "0    2795\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fitting model with 32 features...\n",
      "X shape: (8457, 32)\n",
      "y shape: (8457,)\n",
      "X dtype: float64\n",
      "y dtype: int64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.388857\n",
      "         Iterations: 273\n",
      "         Function evaluations: 274\n",
      "         Gradient evaluations: 274\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "Significant Features (p < 0.05):\n",
      "                                  Feature  Coefficient        P_Value  \\\n",
      "4   iag_trust_confidence_binned_Very High     4.159600  2.668145e-146   \n",
      "3        iag_trust_confidence_binned_High     3.101562   1.858237e-87   \n",
      "2    iag_trust_confidence_binned_Moderate     2.028339   3.219937e-41   \n",
      "8        iag_value_price_binned_Excellent     1.502706   2.081850e-36   \n",
      "1         iag_trust_confidence_binned_Low     1.289624   9.311580e-17   \n",
      "0                                   const    -2.388303   1.099691e-10   \n",
      "30      iag_region_ug_Consumer Claims Ops     0.389568   2.788184e-07   \n",
      "7        iag_value_price_binned_Very Good     0.515470   5.708071e-06   \n",
      "29           iag_product_type_auto_Wheels    -1.075018   1.153310e-02   \n",
      "23        iag_product_type_auto_Home Pack    -0.733326   1.899968e-02   \n",
      "28          iag_product_type_auto_Vehicle    -0.514735   2.934278e-02   \n",
      "9         iag_business_unit_ug_Operations    -0.297514   4.149082e-02   \n",
      "\n",
      "    Odds_Ratio  \n",
      "4    64.045900  \n",
      "3    22.232644  \n",
      "2     7.601451  \n",
      "8     4.493831  \n",
      "1     3.631421  \n",
      "0     0.091785  \n",
      "30    1.476343  \n",
      "7     1.674425  \n",
      "29    0.341292  \n",
      "23    0.480309  \n",
      "28    0.597659  \n",
      "9     0.742662  \n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.826\n",
      "ROC AUC: 0.889\n",
      "McFadden's Pseudo R-squared: 0.387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "class RecommendationAnalysis:\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "        \n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "        \n",
    "        self.features = [\n",
    "            'iag_trust_confidence_scale11',\n",
    "            'iag_value_price_of_policy_reflects_scale11',\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        print(\"\\nStarting data preparation...\")\n",
    "        \n",
    "        # Create copy and drop missing values\n",
    "        df_clean = df.copy()\n",
    "        df_clean = df_clean.dropna(subset=self.features + ['Likely to recommend'])\n",
    "        \n",
    "        print(\"\\nShape after dropping missing values:\", df_clean.shape)\n",
    "        \n",
    "        # Create binned versions of numeric features\n",
    "        df_clean['iag_trust_confidence_binned'] = pd.cut(\n",
    "            df_clean['iag_trust_confidence_scale11'].astype(float),\n",
    "            bins=self.trust_bins,\n",
    "            labels=self.trust_labels\n",
    "        )\n",
    "        \n",
    "        df_clean['iag_value_price_binned'] = pd.cut(\n",
    "            df_clean['iag_value_price_of_policy_reflects_scale11'].astype(float),\n",
    "            bins=self.price_bins,\n",
    "            labels=self.price_labels\n",
    "        )\n",
    "        \n",
    "        print(\"\\nUnique values in binned features:\")\n",
    "        print(\"Trust bins:\", df_clean['iag_trust_confidence_binned'].value_counts())\n",
    "        print(\"\\nPrice bins:\", df_clean['iag_value_price_binned'].value_counts())\n",
    "        \n",
    "        # Define categorical features including binned ones\n",
    "        categorical_features = [\n",
    "            'iag_trust_confidence_binned',\n",
    "            'iag_value_price_binned',\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "        \n",
    "        # Create dummies with proper prefixes\n",
    "        X = pd.get_dummies(df_clean[categorical_features], drop_first=True)\n",
    "        \n",
    "        print(\"\\nDummy variables created:\", X.shape[1])\n",
    "        print(\"Sample column names:\", list(X.columns)[:5])\n",
    "        \n",
    "        # Convert all columns to float64\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Add constant\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Convert target to binary\n",
    "        y = (df_clean['Likely to recommend'] == 'Promote').astype(np.int64)\n",
    "        \n",
    "        print(\"\\nFeature matrix shape:\", X.shape)\n",
    "        print(\"Feature matrix dtype:\", X.dtypes.unique())\n",
    "        print(\"Target vector shape:\", y.shape)\n",
    "        print(\"Target distribution:\\n\", y.value_counts())\n",
    "        \n",
    "        return X, y, df_clean\n",
    "    \n",
    "    def fit_model(self, X, y):\n",
    "        try:\n",
    "            print(f\"\\nFitting model with {X.shape[1]} features...\")\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "            y_np = y.to_numpy(dtype=np.int64)\n",
    "            \n",
    "            print(\"X shape:\", X_np.shape)\n",
    "            print(\"y shape:\", y_np.shape)\n",
    "            print(\"X dtype:\", X_np.dtype)\n",
    "            print(\"y dtype:\", y_np.dtype)\n",
    "            \n",
    "            # Fit model\n",
    "            model = sm.Logit(y_np, X_np)\n",
    "            results = model.fit(method='bfgs', maxiter=1000)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Model fitting failed: {str(e)}\")\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                print(\"\\nFeature names:\", X.columns.tolist())\n",
    "                print(\"\\nSample data:\")\n",
    "                print(X.head())\n",
    "            return None\n",
    "    \n",
    "    def analyze(self, df):\n",
    "        X, y, df_clean = self.prepare_data(df)\n",
    "        results = self.fit_model(X, y)\n",
    "        \n",
    "        if results is not None:\n",
    "            # Calculate predictions\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "            y_pred = results.predict(X_np)\n",
    "            y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "            \n",
    "            # Create summary DataFrame\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Feature': X.columns,\n",
    "                'Coefficient': results.params,\n",
    "                'P_Value': results.pvalues,\n",
    "                'Odds_Ratio': np.exp(results.params)\n",
    "            }).sort_values('P_Value')\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': (y_pred_binary == y).mean(),\n",
    "                'roc_auc': roc_auc_score(y, y_pred),\n",
    "                'classification_report': classification_report(y, y_pred_binary, output_dict=True),\n",
    "                'pseudo_r2': results.prsquared\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'feature_importance': summary_df,\n",
    "                'metrics': metrics,\n",
    "                'model': results\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Run analysis\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "print(\"\\nOriginal data shape:\", df.shape)\n",
    "print(\"\\nColumn types:\")\n",
    "print(df[['iag_trust_confidence_scale11', \n",
    "         'iag_value_price_of_policy_reflects_scale11', \n",
    "         'Likely to recommend']].dtypes)\n",
    "\n",
    "analyzer = RecommendationAnalysis()\n",
    "results = analyzer.analyze(df)\n",
    "\n",
    "if results:\n",
    "    print(\"\\nModel Summary:\")\n",
    "    \n",
    "    print(\"\\nSignificant Features (p < 0.05):\")\n",
    "    significant_features = results['feature_importance'][\n",
    "        results['feature_importance']['P_Value'] < 0.05\n",
    "    ]\n",
    "    print(significant_features[['Feature', 'Coefficient', 'P_Value', 'Odds_Ratio']])\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    metrics = results['metrics']\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print(f\"McFadden's Pseudo R-squared: {metrics['pseudo_r2']:.3f}\")\n",
    "else:\n",
    "    print(\"Model fitting failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "\n",
      "Test Accuracy: 0.7653664302600472\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Detract       0.20      0.01      0.02        92\n",
      "      Passive       0.52      0.38      0.44       355\n",
      "      Promote       0.81      0.95      0.88      1133\n",
      "Super Detract       0.76      0.78      0.77       112\n",
      "\n",
      "     accuracy                           0.77      1692\n",
      "    macro avg       0.58      0.53      0.53      1692\n",
      " weighted avg       0.72      0.77      0.73      1692\n",
      "\n",
      "\n",
      "Feature Importance for each class:\n",
      "\n",
      "Class: Detract\n",
      "                                  Feature  Coefficient\n",
      "15             iag_product_type_auto_Home     0.581401\n",
      "0            iag_trust_confidence_scale11    -0.579054\n",
      "22           iag_product_type_auto_Wheels     0.510256\n",
      "6                 iag_age_band_auto_55-64    -0.449060\n",
      "4                 iag_age_band_auto_35-44    -0.386896\n",
      "5                 iag_age_band_auto_45-54    -0.377738\n",
      "7                   iag_age_band_auto_65+    -0.324599\n",
      "2         iag_business_unit_ug_Operations     0.286409\n",
      "17  iag_product_type_auto_Homeowners Line     0.265393\n",
      "23      iag_region_ug_Consumer Claims Ops    -0.245064\n",
      "\n",
      "Class: Passive\n",
      "                                     Feature  Coefficient\n",
      "22              iag_product_type_auto_Wheels     0.637441\n",
      "19            iag_product_type_auto_Landlord    -0.542827\n",
      "14           iag_product_type_auto_EasyRider     0.371206\n",
      "20  iag_product_type_auto_Private Motor Line    -0.328289\n",
      "7                      iag_age_band_auto_65+     0.327083\n",
      "11                  iag_tenure_band_enum_30+    -0.288876\n",
      "0               iag_trust_confidence_scale11     0.274304\n",
      "17     iag_product_type_auto_Homeowners Line    -0.246751\n",
      "6                    iag_age_band_auto_55-64     0.240593\n",
      "5                    iag_age_band_auto_45-54     0.227005\n",
      "\n",
      "Class: Promote\n",
      "                                       Feature  Coefficient\n",
      "0                 iag_trust_confidence_scale11     1.878050\n",
      "1   iag_value_price_of_policy_reflects_scale11     0.686824\n",
      "21               iag_product_type_auto_Vehicle    -0.558585\n",
      "16             iag_product_type_auto_Home Pack    -0.467673\n",
      "23           iag_region_ug_Consumer Claims Ops     0.432475\n",
      "2              iag_business_unit_ug_Operations    -0.388826\n",
      "20    iag_product_type_auto_Private Motor Line    -0.345392\n",
      "19              iag_product_type_auto_Landlord    -0.328305\n",
      "22                iag_product_type_auto_Wheels    -0.267062\n",
      "14             iag_product_type_auto_EasyRider    -0.214922\n",
      "\n",
      "Class: Super Detract\n",
      "                                       Feature  Coefficient\n",
      "0                 iag_trust_confidence_scale11    -1.573300\n",
      "19              iag_product_type_auto_Landlord     0.951474\n",
      "22                iag_product_type_auto_Wheels    -0.880635\n",
      "21               iag_product_type_auto_Vehicle     0.592458\n",
      "1   iag_value_price_of_policy_reflects_scale11    -0.588146\n",
      "20    iag_product_type_auto_Private Motor Line     0.520777\n",
      "16             iag_product_type_auto_Home Pack     0.517029\n",
      "23           iag_region_ug_Consumer Claims Ops    -0.302050\n",
      "15                  iag_product_type_auto_Home    -0.287964\n",
      "4                      iag_age_band_auto_35-44     0.286105\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6MAAAMWCAYAAAAEYVDaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB150lEQVR4nO3dB3gUVdfA8ZMAKRAINaFJk16kKr2DFBEpFqR3C0hvEelNQERBBAFpiggCUqUJCCqoFCnSlUCkCRIINSFlv+dev913l4AmkMxsZv+/95l3szOzuzdxEvbsOfdcL5vNZhMAAAAAAAzkbeSLAQAAAACgEIwCAAAAAAxHMAoAAAAAMBzBKAAAAADAcASjAAAAAADDEYwCAAAAAAxHMAoAAAAAMBzBKAAAAADAcASjAAAAAADDEYwCALRTp07Js88+K4GBgeLl5SWrVq1K0uc/c+aMft4FCxYk6fOmZLVq1dIbAACeiGAUANzIH3/8Ia+99poUKFBA/Pz8JEOGDFK1alX58MMP5e7du8n62h06dJDDhw/LuHHj5LPPPpMKFSqIVXTs2FEHwurn+aCfowrE1XG1vffee4l+/gsXLsjIkSPlwIEDSTRiAACsL7XZAwAA/GP9+vXy0ksvia+vr7Rv315Kliwp9+7dkx9++EEGDhwoR44ckdmzZyfLa6sAbffu3TJ06FDp2bNnsrxG3rx59eukSZNGzJA6dWq5c+eOrF27Vl5++WWXY4sXL9bBf2Rk5CM9twpGR40aJfny5ZMyZcok+HGbN29+pNcDAMAKCEYBwA2EhoZKq1atdMC2bds2yZEjh+NYjx495Pfff9fBanK5cuWKvs2YMWOyvYbKOqqAzywqyFdZ5iVLlsQLRr/44gt57rnnZMWKFYaMRQXFadOmFR8fH0NeDwAAd0SZLgC4gUmTJsmtW7fk008/dQlE7QoWLCi9e/d23I+JiZExY8bIk08+qYMslZF7++23JSoqyuVxan+TJk10dvWZZ57RwaAqAV60aJHjHFVeqoJgRWVgVdCoHmcvb7V/7Uw9Rp3nbMuWLVKtWjUd0AYEBEiRIkX0mP5rzqgKvqtXry7p0qXTj33hhRfk2LFjD3w9FZSrManz1NzWTp066cAuoVq3bi0bNmyQ69evO/bt2bNHl+mqY/cLDw+XAQMGSKlSpfT3pMp8GzVqJAcPHnSc891338nTTz+tv1bjsZf72r9PNSdUZbn37dsnNWrU0EGo/edy/5xRVSqt/hvd//03aNBAMmXKpDOwAABYBcEoALgBVTqqgsQqVaok6PyuXbvK8OHDpVy5cjJ16lSpWbOmTJgwQWdX76cCuBdffFHq168vU6ZM0UGNCuhU2a/SokUL/RzKq6++queLfvDBB4kav3ouFfSqYHj06NH6dZo2bSo//vjjvz7u22+/1YHW5cuXdcDZr18/2bVrl85gquD1fiqjefPmTf29qq9VwKfKYxNKfa8qUFy5cqVLVrRo0aL6Z3m/06dP60ZO6nt7//33dbCu5tWqn7c9MCxWrJj+npXu3bvrn5/aVOBpd/XqVR3EqhJe9bOtXbv2A8en5gZny5ZNB6WxsbF63yeffKLLeadPny45c+ZM8PcKAIDbswEATBUREWFTf45feOGFBJ1/4MABfX7Xrl1d9g8YMEDv37Ztm2Nf3rx59b6dO3c69l2+fNnm6+tr69+/v2NfaGioPm/y5Mkuz9mhQwf9HPcbMWKEPt9u6tSp+v6VK1ceOm77a8yfP9+xr0yZMragoCDb1atXHfsOHjxo8/b2trVv3z7e63Xu3NnlOZs3b27LkiXLQ1/T+ftIly6d/vrFF1+01a1bV38dGxtry549u23UqFEP/BlERkbqc+7/PtTPb/To0Y59e/bsife92dWsWVMfmzVr1gOPqc3Zpk2b9Pljx461nT592hYQEGBr1qzZf36PAACkNGRGAcBkN27c0Lfp06dP0PnffPONvlVZRGf9+/fXt/fPLS1evLgug7VTmTdVQquyfknFPtd09erVEhcXl6DHXLx4UXefVVnazJkzO/Y/9dRTOotr/z6dvf766y731felso72n2FCqHJcVVp76dIlXSKsbh9UoquoEmhv73/+qVSZSvVa9hLk/fv3J/g11fOoEt6EUMvrqI7KKtuqMrmqbFdlRwEAsBqCUQAwmZqHqKjy04Q4e/asDpDUPFJn2bNn10GhOu4sT5488Z5Dlepeu3ZNksorr7yiS2tV+XBwcLAuF162bNm/Bqb2carA7n6q9PXvv/+W27dv/+v3or4PJTHfS+PGjXXgv3TpUt1FV833vP9naafGr0qYCxUqpAPKrFmz6mD+0KFDEhERkeDXzJUrV6KaFanlZVSAroL1adOmSVBQUIIfCwBASkEwCgBuEIyquYC//fZboh53fwOhh0mVKtUD99tstkd+Dft8Rjt/f3/ZuXOnngParl07HaypAFVlOO8/93E8zvdip4JKlXFcuHChfP311w/Niirjx4/XGWg1//Pzzz+XTZs26UZNJUqUSHAG2P7zSYxff/1Vz6NV1BxVAACsiGAUANyAapDzxx9/6LU+/4vqfKsCIdUB1tlff/2lu8TaO+MmBZV5dO48a3d/9lVR2dq6devqRj9Hjx6VcePG6TLY7du3P/T7UE6cOBHv2PHjx3UWUnXYTQ4qAFUBn8pGP6jpk93y5ct1syHV5Vidp0po69WrF+9nktAPBhJCZYNVSa8qr1YNkVSnZdXxFwAAqyEYBQA3MGjQIB14qTJXFVTeTwWqqtOqvcxUub/jrQoCFbVeZlJRS8eoclSV6XSe66kyivcvgXI/1TlWuX+5GTu1hI06R2UonYM7lSFW3WPt32dyUAGmWhrno48+0uXN/5aJvT/r+tVXX8n58+dd9tmD5gcF7ok1ePBgCQsL0z8X9d9ULa2juus+7OcIAEBKldrsAQAA/gn61BIjqrRVzZds3769Xpvy3r17eqkTFQCpRj9K6dKldXAye/ZsHfyoZUZ++eUXHbw0a9bsocuGPAqVDVTBUfPmzaVXr156Tc+ZM2dK4cKFXRr4qGY7qkxXBcIq46lKTD/++GPJnTu3Xnv0YSZPnqyXPKlcubJ06dJF7t69q5cwUWuIqqVekovK4r7zzjsJylir701lKtWyO6pkVs0zVcvw3P/fT83XnTVrlp6PqoLTihUrSv78+RM1LpVJVj+3ESNGOJaamT9/vl6LdNiwYTpLCgCAVZAZBQA3odblVBlItSao6krbo0cPGTJkiF5vU63bqRrZ2M2dO1evr6nKN/v06aODmJCQEPnyyy+TdExZsmTRWdC0adPq7K0KeNUan88//3y8savmQvPmzdPjnjFjhp5nqcalAsuHUSWvGzdu1K+j1k1VjXsqVaqk1ydNbCCXHN5++23dpVjNFe3du7cOwFW34ieeeMLlvDRp0uifjcqkqo6/ar3WHTt2JOq1VMlw586dpWzZsjJ06FCXjsHqtdU18NNPPyXZ9wYAgNm81PouZg8CAAAAAOBZyIwCAAAAAAxHMAoAAAAAMBzBKAAAAADAcASjAAAAAADDEYwCAAAAAAxHMAoAAAAAMBzBKAAAAADAcKnFgiJjzB4BkPzu3os1ewhAsvJJzeelAJDSpfPxkpTIv2xPcRd3f/1IrIp/6QEAAAAAhiMYBQAAAAAYzpJlugAAAADwyLzI2RmBnzIAAAAAwHAEowAAAAAAw1GmCwAAAADOvFJmF+CUhswoAAAAAMBwBKMAAAAAAMNRpgsAAAAAzuimawh+ygAAAAAAw5EZBQAAAABnNDAyBJlRAAAAAIDhCEYBAAAAAIajTBcAAAAAnNHAyBD8lAEAAAAAhiMYBQAAAAAYjjJdAAAAAHBGN11DkBkFAAAAABiOYBQAAAAAYDjKdAEAAADAGd10DcFPGQAAAABgODKjAAAAAOCMBkaGIDMKAAAAADAcwSgAAAAAwHCU6QIAAACAMxoYGYKfMgAAAADAcASjAAAAAADDUaYLAAAAAM7opmsIMqMAAAAAAMMRjAIAAAAADEeZLgAAAAA4o5uuIfgpAwAAAAAMR2YUAAAAAJzRwMgQZEYBAAAAAIYjGAUAAAAAGI4yXQAAAABwRgMjQ/BTBgAAAAAYjmAUAAAAAGA4ynQBAAAAwBlluobgpwwAAAAAMBzBKAAAAADAcJTpAgAAAIAzby+zR+ARyIwCAAAAAAxHMAoAAAAA9zcwcpctEXbu3CnPP/+85MyZU7y8vGTVqlUux202mwwfPlxy5Mgh/v7+Uq9ePTl16pTLOeHh4dKmTRvJkCGDZMyYUbp06SK3bt1yOefQoUNSvXp18fPzkyeeeEImTZokj4JgFAAAAAAs4Pbt21K6dGmZMWPGA4+roHHatGkya9Ys+fnnnyVdunTSoEEDiYyMdJyjAtEjR47Ili1bZN26dTrA7d69u+P4jRs35Nlnn5W8efPKvn37ZPLkyTJy5EiZPXt2osfrZVPhscVExpg9AiD53b0Xa/YQgGTlk5rPSwEgpUvnkzLnXvrXGSfu4u62oY/0OJUZ/frrr6VZs2b6vgr7VMa0f//+MmDAAL0vIiJCgoODZcGCBdKqVSs5duyYFC9eXPbs2SMVKlTQ52zcuFEaN24s586d04+fOXOmDB06VC5duiQ+Pj76nCFDhugs7PHjxxM1Rv6lBwAAAABnXl5us0VFRelspPOm9iVWaGioDiBVaa5dYGCgVKxYUXbv3q3vq1tVmmsPRBV1vre3t86k2s+pUaOGIxBVVHb1xIkTcu3atUSNiWAUAAAAANzUhAkTdNDovKl9iaUCUUVlQp2p+/Zj6jYoKMjleOrUqSVz5swu5zzoOZxfI6FY2gUAAAAA3FRISIj069fPZZ+vr69YAcEoAAAAADhLZBfb5OTr65skwWf27Nn17V9//aW76dqp+2XKlHGcc/nyZZfHxcTE6A679serW/UYZ/b79nMSyn1+ygAAAACAZJE/f34dLG7dutWxT80/VXNBK1eurO+r2+vXr+suuXbbtm2TuLg4PbfUfo7qsBsdHe04R3XeLVKkiGTKlClRYyIYBQAAAAALuHXrlhw4cEBv9qZF6uuwsDDdXbdPnz4yduxYWbNmjRw+fFjat2+vO+TaO+4WK1ZMGjZsKN26dZNffvlFfvzxR+nZs6futKvOU1q3bq2bF6n1R9USMEuXLpUPP/wwXilxQlCmCwAAAADOVCfbFGjv3r1Su3Ztx317gNihQwe9fMugQYP0WqRq3VCVAa1WrZpeusXPz8/xmMWLF+sAtG7durqLbsuWLfXapHaqgdLmzZulR48eUr58ecmaNasMHz7cZS3ShGKdUSCFYp1RWB3rjAJAypdi1xmtP1Hcxd0tg8WqyIwCAAAAgJs2MLIyfsoAAAAAAMMRjAIAAAAADEeZLgAAAABYoIFRSkNmFAAAAABgOIJRAAAAAIDhKNMFAAAAAGd00zUEP2UAAAAAgOEIRgEAAAAAhqNMFwAAAACc0U3XEGRGAQAAAACeGYwWKFBArl69Gm//9evX9TEAAAAAMLSBkbtsFuYW392ZM2ckNjY23v6oqCg5f/68KWMCAAAAAFh0zuiaNWscX2/atEkCAwMd91VwunXrVsmXL59JowMAAAAAWDIYbdasmb718vKSDh06uBxLkyaNDkSnTJli0ugAAAAAeCQaGFk/GI2Li9O3+fPnlz179kjWrFnNHA4AAAAAwJOWdgkNDTV7CAAAAAAAT2tg1KtXL5k2bVq8/R999JH06dPHlDEBAAAA8FBmd9D1opuuYVasWCFVq1aNt79KlSqyfPlyU8YEAAAAALB4MKrWGHXupGuXIUMG+fvvv00ZEwAAAADA4sFowYIFZePGjfH2b9iwQQoUKGDKmAAAAAB4KLNLc708o0zXLRoY9evXT3r27ClXrlyROnXq6H1qjVG1rMsHH3xg9vAAAAAAAFYMRjt37ixRUVEybtw4GTNmjN6n1hidOXOmtG/f3uzhAQAAAPAkrDNqCC+bzWYTN6Kyo/7+/hIQEPDIzxEZk6RDAtzS3XuxZg8BSFY+qa1dmgQAniCdT8oM6vybzhR3cXfNG2JVbpEZdZYtWzazhwAAAAAA8JRgVC3hsmzZMgkLC5N79+65HNu/f79p4wIAAADgYSzeOMhduMVPedq0adKpUycJDg6WX3/9VZ555hnJkiWLnD59Who1amT28AAAAAAAVgxGP/74Y5k9e7ZMnz5dfHx8ZNCgQbJlyxbp1auXREREmD08PMS+vXvkrTdfl3q1qknpEkVk29ZvzR4SkGQWzZsjlcoWl6mTJzj2nfszTAb3e0sa1q4qdao9LUMH9ZWrV1kLGSnHvLmfSNtWL0q1iuWkbs0q0q9XDzkTetrlnBVfLZVundpJ9UrlpVyponLzxg3TxgskFtc4kLK4RTCqSnOrVKmiv1bNi27evKm/bteunSxZssTk0eFh7t69I0WKFJGQd0aYPRQgSR09cli+XrFMChYq4nK9936zm+6u99Hs+TJ7/mKJjo6Wgb17SFxcnKnjBRLzIeLLrVrLwsVLZebseRITEyNvvtZV7t654zgnMjJSqlStLp27vmbqWIFHwTWOJO2m6y6bhbnFnNHs2bNLeHi45M2bV/LkySM//fSTlC5dWkJDQ8XNmv3CSbXqNfUGWMmdO7dlxNuDJGTYKJk/9xPH/kMHfpWLF87LoiUrJN3/d/sePnqC1K9ZSfb+8pM8U+mfD9QAdzZj1lyX+6PGTtDZo6NHj0j5Ck/rfW3addC3e/f8bMoYgcfBNQ6kLG6RGa1Tp46sWbNGf63mjvbt21fq168vr7zyijRv3tzs4QHwIO9NGCtVq9eMF1yqxmpeXl6SxsfHsc/H11e8vb3l4AGarCFlunnrn0qkwMBAs4cCJAuuccC9uUVmVM0XtZe59ejRQzcv2rVrlzRt2lRee40SCgDG2LLxGzlx/KjM+3xZvGMlS5UWP39/mfHhFHmjZx+xiU1mfPi+xMbGytW/r5gyXuBxqH9335s4XsqULScFCxU2ezhAkuMax2Ohm65nBKOqln/8+PHSuXNnyZ07t97XqlUrvSVEVFSU3pzZUvmKr69vsowXgDX9demivD95gkybOfeBfz8yZc4s4ydNlUnjR8uyJZ/rjGj9ho2lSLHi4sU/WEiB3h03Wv74/ZTMW/iF2UMBkgXXOOD+TH8HlTp1apk0aZIOSh/FhAkTdOmF8zZ54v+6XwJAQhw/dkSuhV+Vjq1flKoVSunt1317dOCpvlYZ0IqVq8qKtZtkw9YfZOP2H2Xk2Ily5fJfkuv/P0gDUtKb9O93fCezP10kwdmzmz0cIMlxjeOxmd20yIsGRoapW7eu7NixQ/Lly5fox4aEhEi/fv3iZUYBIDEqPFNZFn+12mXf2BFDJW/+/NKuY1dJlSqVY3/GTJn0rWpcdC08XKrXrGP4eIFHoZoCThw/RrZv+1bmzFvEBymwHK5xIGVxi2C0UaNGMmTIEDl8+LCUL19e0qVL53JczR19GFVOd39JXeSjJVmRSHdu39bL8tidP3dOjh87prPTOXLmNHVsQGKpvztPFizksk/NEQ0MzOjYv271SsmX/0kdjB4+dECvQdqqTXvJmy+/SaMGEp8t2vDNOpn64QxJmy6d/P3/850DAtKLn5+f/lrtu/r33/Ln//99P3XqpP79yJ4jh/59ANwZ1ziQsnjZ3GDtFDX36mFU90pVHpcYBKPG2PPLz9K1U/t4+5u+0FzGjH/XlDF5krv3Evd7gcR7o2sHKVykqPQdGKLvq4ZF69d+LTciIiRHzlzS/MVX5NW2HfTfKSQ9n9SmzySxnHKlij5w/8gx46Vpsxb661kfT5fZM2f86zmAu+Iadz/pfFLmv5FpW84Td3FnRWexKrcIRpMawSg8AcEorI5gFABSPoLRx3fHwsGoW/xLv2jRongdce3r+qljAAAAAABrcYvMqGoMcvHiRQkKCnLZf/XqVb2PMl0gPjKjsDoyowCQ8qXUzGi6F+eLu7i9vJNYlVv8S6/i4QfNuTp37pxuhgMAAAAAsBZTu+mWLVtWB6FqU8u7qDVH7VQ2NDQ0VBo2bGjmEAEAAAAAVgtGmzVrpm8PHDggDRo0kICAAMcxHx8fve5oy5YtTRwhAAAAAI+TMquLUxxTg9ERI0boWxV0vvLKK471nwAAAAAA1uYWc0Y7dOggkZGRMnfuXAkJCZHw8HC9f//+/XL+/HmzhwcAAADAg9inErrDZmWmZkbtDh06JPXq1dPNis6cOSPdunWTzJkzy8qVKyUsLIzlXQAAAADAYtwiM9q3b1/p2LGjnDp1yqVUt3HjxrJz505TxwYAAAAAsGhmdO/evTJ79ux4+3PlyiWXLl0yZUwAAAAAPJPVy2PdhVtkRn19feXGjRvx9p88eVKyZctmypgAAAAAABYPRps2bSqjR4+W6OhoxycRaq7o4MGDWdoFAAAAACzILYLRKVOmyK1bt3QW9O7du1KzZk0pWLCgpE+fXsaNG2f28AAAAAB4ELM76HrRTdc4qovuli1b5Mcff5SDBw/qwLRcuXK6wy4AAAAAwHpMD0bj4uJkwYIFehkXtayLiv7z588v2bNnF5vNZvlPAwAAAADAE5lapquCTTVftGvXrnL+/HkpVaqUlChRQs6ePauXemnevLmZwwMAAADggcwuzfWiTDf5qYyoWkd069atUrt2bZdj27Ztk2bNmsmiRYukffv2po0RAAAAAGCxzOiSJUvk7bffjheIKnXq1JEhQ4bI4sWLTRkbAAAAAA/l5UabhZkajB46dEgaNmz40OONGjXSDY0AAAAAANZiajAaHh4uwcHBDz2ujl27ds3QMQEAAAAALD5nNDY2VlKnfvgQUqVKJTExMYaOCQAAAIBns3rjIHeR2uxuuqprrq+v7wOPR0VFGT4mAAAAAIDFg9EOHTr85zl00gUAAAAA6zE1GJ0/f76ZLw8AAAAA8VCm6wENjAAAAAAAnolgFAAAAADgWWW6AAAAAOBuKNM1BplRAAAAAIDhyIwCAAAAgBMyo8YgMwoAAAAAMBzBKAAAAADAcJTpAgAAAIAzqnQNQWYUAAAAAGA4glEAAAAAgOEo0wUAAAAAJ3TTNQaZUQAAAACA4QhGAQAAAACGo0wXAAAAAJxQpmsMMqMAAAAAAMORGQUAAAAAJ2RGjUFmFAAAAABgOIJRAAAAAIDhKNMFAAAAAGdU6RqCzCgAAAAAwHAEowAAAAAAw1GmCwAAAABO6KZrDDKjAAAAAADDEYwCAAAAAAxHmS4AAAAAOKFM1xhkRgEAAAAAhiMzCgAAAABOyIwag8woAAAAAMBwBKMAAAAAAMNRpgsAAAAATijTNQaZUQAAAACA4QhGAQAAAACGo0wXAAAAAJxRpWsIMqMAAAAAAMMRjAIAAAAADEeZLgAAAAA4oZuuMciMAgAAAAAMR2YUAAAAAJyQGTUGmVEAAAAAgOEIRgEAAAAAhqNMFwAAAACcUKZrDDKjAAAAAADDEYwCAAAAAAxHmS4AAAAAOKNK1xBkRgEAAAAAhiMYBQAAAAAYjjJdAAAAAHBCN11jkBkFAAAAABiOzCgAAAAAOCEzagwyowAAAAAAwxGMAgAAAAAMR5kuAAAAADihTNcYZEYBAAAAAIYjGAUAAAAAGI4yXQAAAABwQpmuMciMAgAAAAAMRzAKAAAAADAcZboAAAAA4IwqXUOQGQUAAAAAC4iNjZVhw4ZJ/vz5xd/fX5588kkZM2aM2Gw2xznq6+HDh0uOHDn0OfXq1ZNTp065PE94eLi0adNGMmTIIBkzZpQuXbrIrVu3kny8ZEaBFCriTrTZQwCSFdc4rK5IzvRmDwGAxRoYTZw4UWbOnCkLFy6UEiVKyN69e6VTp04SGBgovXr10udMmjRJpk2bps9RQasKXhs0aCBHjx4VPz8/fY4KRC9evChbtmyR6Oho/Rzdu3eXL774IknH62VzDpMtIjLG7BEAye/S9UizhwAkK4JRWB3BKDyBXwpNfRXo9424i9PvN07wuU2aNJHg4GD59NNPHftatmypM6Cff/65zormzJlT+vfvLwMGDNDHIyIi9GMWLFggrVq1kmPHjknx4sVlz549UqFCBX3Oxo0bpXHjxnLu3Dn9+KRCmS4AAAAAWECVKlVk69atcvLkSX3/4MGD8sMPP0ijRo30/dDQULl06ZIuzbVTWdOKFSvK7t279X11q0pz7YGoos739vaWn3/+OUnHm0I/qwAAAAAA65fpRkVF6c2Zr6+v3u43ZMgQuXHjhhQtWlRSpUql55COGzdOl90qKhBVVCbUmbpvP6Zug4KCXI6nTp1aMmfO7DgnqZAZBQAAAAA3NWHCBJ29dN7UvgdZtmyZLF68WM/t3L9/v54X+t577+lbd0RmFAAAAADcVEhIiPTr189l34OyosrAgQN1dlTN/VRKlSolZ8+e1cFrhw4dJHv27Hr/X3/9pbvp2qn7ZcqU0V+rcy5fvuzyvDExMbrDrv3xSYXMKAAAAAA4UVW67rL5+vrqJVact4cFo3fu3NFzO52pct24uDj9teqeqwJKNa/UTpX1qrmglStX1vfV7fXr12Xfvn2Oc7Zt26afQ80tTUpkRgEAAADAAp5//nk9RzRPnjx6aZdff/1V3n//fencubNjLmyfPn1k7NixUqhQIcfSLqpDbrNmzfQ5xYoVk4YNG0q3bt1k1qxZemmXnj176mxrUnbSVQhGAQAAAMACpk+froPLN998U5faquDxtddek+HDhzvOGTRokNy+fVuvG6oyoNWqVdNLt9jXGFXUvFMVgNatW1dnWtXyMGpt0qTGOqNACsU6o7A61hmF1bHOKDxBSl1ntNDAjeIuTk1uKFbFnFEAAAAAgOFS6GcVAAAAAJA83GiZUUsjMwoAAAAAMBzBKAAAAADAcJTpAgAAAIATtQQKkh+ZUQAAAACA4QhGAQAAAACGo0wXAAAAAJxQpWsMMqMAAAAAAMMRjAIAAAAADEeZLgAAAAA48famTtcIZEYBAAAAAIYjMwoAAAAATmhgZAwyowAAAAAAwxGMAgAAAAAMR5kuAAAAADjxok7XEGRGAQAAAACGIxgFAAAAABiOMl0AAAAAcEKVrjHIjAIAAAAADEcwCgAAAAAwHGW6AAAAAOCEbrrGIDMKAAAAADAcmVEAAAAAcEJm1BhkRgEAAAAAhiMYBQAAAAAYjjJdAAAAAHBCla4xyIwCAAAAAAxHMAoAAAAAMBxlugAAAADghG66xiAzCgAAAAAwHMEoAAAAAMBwlOkCAAAAgBOqdI1BZhQAAAAAYDgyowAAAADghAZGxiAzCgAAAAAwHMEoAAAAAMBwlOkCAAAAgBOqdI1BZhQAAAAAYDiCUQAAAACA4SjTBQAAAAAndNM1BplRAAAAAIDhCEYBAAAAAIajTBcAAAAAnFClawwyowAAAAAAw5EZBQAAAAAnNDAyBplRAAAAAIDhCEYBAAAAAIajTBcAAAAAnFClawwyowAAAAAAwxGMAgAAAAAMR5kuAAAAADihm64xyIwCAAAAAAxHMAoAAAAAMBxlugAAAADghCpdY5AZBQAAAAB4bjB6/fp1mTt3roSEhEh4eLjet3//fjl//rzZQwMAAADgYQ2M3GWzMrco0z106JDUq1dPAgMD5cyZM9KtWzfJnDmzrFy5UsLCwmTRokVmDxEAAAAAYLXMaL9+/aRjx45y6tQp8fPzc+xv3Lix7Ny509SxAQAAAAAsmhnds2ePfPLJJ/H258qVSy5dumTKmAAAAAB4JotXx7oNt8iM+vr6yo0bN+LtP3nypGTLls2UMQEAAAAALB6MNm3aVEaPHi3R0dH6vpqoq+aKDh48WFq2bGn28AAAAAAAVgxGp0yZIrdu3ZKgoCC5e/eu1KxZUwoWLCjp06eXcePGmT08AAAAAB7E7A66XnTTNY7qortlyxb54YcfdGddFZiWK1dOd9gFAAAAAFiPWwSjf/75pzzxxBNSrVo1vQEAAAAArM0tynTz5cunS3PnzJkj165dM3s4AAAAADyY2aW5Xh5SpusWwejevXvlmWee0U2McuTIIc2aNZPly5dLVFSU2UMDAAAAAFg1GC1btqxMnjxZd9DdsGGDXs6le/fuEhwcLJ07dzZ7eAAAAAA8iEpIustmZW4RjNqpNHTt2rV1ue63334r+fPnl4ULF5o9LAAAAACAlYPRc+fOyaRJk6RMmTK6bDcgIEBmzJhh9rAAAAAAAFbspvvJJ5/IF198IT/++KMULVpU2rRpI6tXr5a8efOaPTQAAAAAHsbqjYPchVsEo2PHjpVXX31Vpk2bJqVLlzZ7OAAAAAAATwhGVeMiPn1Iefbt3SML5n0qx47+JleuXJGp02ZInbr1zB4WkGCHD+yTr75YIKeOH5Pwq1dkxISpUqVGHcfxzz6dKd99u1GuXL4kadKkkYJFikun7j2laImn4j3XvXv3pHe3tnL69xPy8fyl8mThogZ/N4Crr5fMl19+2C7n/zwjPr6+Urj4U9K261uS84l8jnO+Xb9Sfti2UUJ/PyF379yW+V9vl3QB6eM91/6ff5Dln8+Rs6d/Fx8fHyn2VDkZNGqKwd8R8Pg+nTNbpn0wRdq0bS+DQoaaPRzA45kWjB46dEhKliwp3t7ecvjw4X8996mn4r/xg/nu3r0jRYoUkWYtWkq/3j3NHg6QaJF370qBgkWkwXPNZPTb/eIdz/VEXunRL0Ry5MwtUVGR8vXSzyWk7xsyf+layZgps8u5n348VbJkzaaDUcAdHD20Xxo0fUmeLFJcYmNjZcm8GTJ2SE95f+5X4ufvr89R13WZp6vo7YtPP3rg8/z0/Vb5ZOo4ebXTm1Ky7NMSFxsrYWf+MPi7AR7fb4cPyfKvvpTChYuYPRSkAOTJLB6MqiZFly5dkqCgIP21yozabDbHcft9dav+EYX7qVa9pt6AlOrpytX09jB1nm3scr97rwGycd3XEvrHKSlboaJj/57dP8i+X3bLsHFTZM9PPyTrmIGEGjphusv9HgNHSteX6svpU8ek+FPl9L7nWrTWt0cO7n3gc8TGxsiCj6dIu269pE6jZo79ufMWSNaxA0ntzu3bEjJ4oIwYNVbmfDLT7OEAMDsYDQ0N1euJ2r8GAHcWHR0t36xeoUsYCxQs7Nh/LfyqfDBxlIyY8IH4+vmZOkbg39y5fUvfBqTPkODHhJ46LuF/XxYvL28Z9HpruX7tquR7soi07dZL8uQvmIyjBZLW+LGjpUaNmlKpchWCUcCNmBaMOnfKpWsuAHf10487ZMKIwRIVGSmZs2SVCR/MksCMmfQxVb3x3rhh8lyzl6RwsRJy6eJ5s4cLPFBcXJwsmDlFipQonagg8q//v6a/+my2tH+9rwQF55S1yz+XUQNekw/nr5SADIHJOGogaWz4Zr0cO3ZUvli63OyhIAWhn40HrTO6cOFCWb9+veP+oEGDJGPGjFKlShU5e/bsvz42KipKbty44bKpfQCQFMqUe1o+XrBMps5aJBUqVZVxwwbq7JCyevkXuunLK+26mD1M4F99On2i/HnmD+kzdHyiHmefPtOidWepVL2uFChcTN4cMEJPptq989tkGi2QdC5dvCiT3h0nEyZOFl9fX7OHA8Adg9Hx48eL//83U9i9e7d89NFHMmnSJMmaNav07dv3Xx87YcIECQwMdNkmT5xg0MgBWJ2ff1rJlTuPFCv5lPQLGSWpUqWWjWtX6WMH9u2RY78dkia1n5ZGNcpJp1ee1/t7dm0tk8e8Y/LIgf8Foqob7ojJsyRLtuBEPTZj5qzx5oim8fGR4By55O/Ll5J8rEBSO3r0iIRfvSqtXmoh5Z4qrre9e36RLxZ/pr+mLwkeRiVG3WWzMrdY2uXPP/+UggX/KRtatWqVvPjii9K9e3epWrWq1KpV618fGxISIv36uXbBtKXiky8AycMWFyfR0ff012/2GSwdu/dwHLt65Yq83e8NeXvUJClaopSJowT+yWrO+2iS/PLjdzLyvU8kKEeuRD9HgUJFJU0aH7nw5xkpWrKM3hcTEyNXLl2UbME5kmHUQNKqWKmSLF+11mXfiKEhkq9AAenUpZukSpXKtLEBcJNgNCAgQK5evSp58uSRzZs3O4JLPz8/uXv37r8+VpVc3F92ERmTrMOFU2c6tUas3flz5+T4sWM6O50jZ05TxwYkxN07d+TCuf9dw5cunJc/Th6X9BkCJUNgoHyxcK5UrlZLMmfNKjeuX5c1K7+Uv/++LNVr19fnB2XPES+LquTMlVuyBSUuAwUkR0ZUrSGq1gP1T5tWrof/rfenTRcgPr7/NNtS+66HX5VL58/p+2Ghv4u/f1rJGpRdzwdV59Zv0lKWLZotWbJll2zB2WXNss/0uZVqsK403F+6dAFSqND/ms4p6vchY2DGePsBeGgwWr9+fenatauULVtWTp48KY0b/7OcwpEjRyRfvv8tzg33cuTIb9K1U3vH/fcm/VMe3fSF5jJm/LsmjgxImJPHj8igt7o67n8y/T19W79RU+k18B05dzZUxmxYIzcirkv6DBl1k6IpH8+XfAXoIgr3t3ntP81aRg54zWW/mvNZq8E/JeWb162Q5Z/NcRwb0a9bvHPadu8t3qlSyUcTh8u9e1FSsGgJGT55ZqK68gJASuNt9fpYN+Flc17c0yTXr1+Xd955R5frvvHGG9KwYUO9f8SIEeLj4yNDhw5N1PORGYUnuHQ90uwhAMkq4k602UMAklWRnOnNHgKQ7PzcIvWVePU/+kncxZaelcSq3CIYTWoEo/AEBKOwOoJRWB3BKDwBwejj22LhYNQtuulu3LhRfvjhB8f9GTNmSJkyZaR169Zy7do1U8cGAAAAwLOY3UHXy0O66bpFMDpw4EC9Pqhy+PBh6d+/v543GhoaGq9TLgAAAAAg5XOLxLkKOosXL66/XrFihTRp0kSvPbp//35HMyMAAAAAgHW4RTCqmhTduXNHf/3tt99K+/b/dGjNnDmzI2MKAAAAAEbwsnp9rJtwi2C0WrVquhy3atWq8ssvv8jSpUv1frXMS+7cuc0eHgAAAADAinNGP/roI0mdOrUsX75cZs6cKbly5dL7N2zY4FjmBQAAAACM4O3lPpuVsbQLkEKxtAusjqVdYHUs7QJPkFKXdmk082dxFxveqChW5XaXR2RkpNy7d89lX4YMGUwbDwAAAADAosHo7du3ZfDgwbJs2TK5evVqvOOxsbGmjAsAAACA56GBkQfNGR00aJBs27ZNzxf19fWVuXPnyqhRoyRnzpyyaNEis4cHAAAAALBiZnTt2rU66KxVq5Z06tRJqlevLgULFpS8efPK4sWLpU2bNmYPEQAAAABgtcxoeHi4FChQwDE/VN23L/myc+dOk0cHAAAAwJOoKl132azMLYJRFYiGhobqr4sWLarnjtozphkzZjR5dAAAAAAASwajqjT34MGD+ushQ4bIjBkzxM/PT/r27SsDBw40e3gAAAAAACvNGY2Li5PJkyfLmjVr9HIuFy5ckBEjRsjx48dl3759et7oU089ZeYQAQAAAHgYL7F4faybMDUYHTdunIwcOVLq1asn/v7+8uGHH8rly5dl3rx5unkRAAAAAMCaTA1GVQfdjz/+WF577TV9/9tvv5XnnntOL+3i7e0WFcQAAAAAPIw3iVFDmBrxhYWFSePGjR33VYZULTCrynUBAAAAANZlajAaExOjGxU5S5MmjURHR5s2JgAAAACAxct0bTabdOzYUXx9fR37IiMj5fXXX5d06dI59q1cudKkEQIAAADwNKpaExYPRjt06BBvX9u2bU0ZCwAAAADAQ4LR+fPnm/nyAAAAAABPDEYBAAAAwN1QpWsM1k8BAAAAABiOYBQAAAAAYDjKdAEAAADAiTd1uoYgMwoAAAAAMByZUQAAAABwQmLUGGRGAQAAAACGIxgFAAAAABiOMl0AAAAAcOJFna4hyIwCAAAAAAxHMAoAAAAAMBxlugAAAADghCpdY5AZBQAAAAAYjmAUAAAAAGA4ynQBAAAAwIk3dbqGIDMKAAAAABZx/vx5adu2rWTJkkX8/f2lVKlSsnfvXsdxm80mw4cPlxw5cujj9erVk1OnTrk8R3h4uLRp00YyZMggGTNmlC5dusitW7eSfKwEowAAAABgAdeuXZOqVatKmjRpZMOGDXL06FGZMmWKZMqUyXHOpEmTZNq0aTJr1iz5+eefJV26dNKgQQOJjIx0nKMC0SNHjsiWLVtk3bp1snPnTunevXuSj9fLpkJji4mMMXsEQPK7dP1/fzAAK4q4E232EIBkVSRnerOHACQ7vxQ6KbDVwl/FXXzZoWyCzx0yZIj8+OOP8v333z/wuAr9cubMKf3795cBAwbofRERERIcHCwLFiyQVq1aybFjx6R48eKyZ88eqVChgj5n48aN0rhxYzl37px+fFIhMwoAAAAAbioqKkpu3Ljhsql9D7JmzRodQL700ksSFBQkZcuWlTlz5jiOh4aGyqVLl3Rprl1gYKBUrFhRdu/ere+rW1Waaw9EFXW+t7e3zqQmJYJRAAAAAHDi5eXlNtuECRN0wOi8qX0Pcvr0aZk5c6YUKlRINm3aJG+88Yb06tVLFi5cqI+rQFRRmVBn6r79mLpVgayz1KlTS+bMmR3nJJUUmjgHAAAAAOsLCQmRfv36uezz9fV94LlxcXE6ozl+/Hh9X2VGf/vtNz0/tEOHDuJuyIwCAAAAgJvy9fXVXW2dt4cFo6pDrprv6axYsWISFhamv86ePbu+/euvv1zOUfftx9Tt5cuXXY7HxMToDrv2c5IKwSgAAAAAOPH2cp8tMVQn3RMnTrjsO3nypOTNm1d/nT9/fh1Qbt261XFczUFVc0ErV66s76vb69evy759+xznbNu2TWdd1dzSpESZLgAAAABYQN++faVKlSq6TPfll1+WX375RWbPnq03Rc1B7dOnj4wdO1bPK1XB6bBhw3SH3GbNmjkyqQ0bNpRu3brp8t7o6Gjp2bOn7rSblJ10FYJRAAAAALCAp59+Wr7++ms9z3T06NE62Pzggw/0uqF2gwYNktu3b+t1Q1UGtFq1anrpFj8/P8c5ixcv1gFo3bp1dRfdli1b6rVJkxrrjAIpFOuMwupYZxRWxzqj8AQpdZ3Rtp8fFHfxedvSYlUJujwOHTqU4Cd86qmnHmc8AAAAAAAPkKBgtEyZMrq++GFJVPsxdRsbG5vUYwQAAAAAeGIwGhoamvwjAQAAAAA34JXILrZIxmDU3goYAAAAAADT1hn97LPP9Bo2qrXv2bNn9T7VpWn16tVJMigAAAAAMIuafugum5UlOhidOXOm9OvXTxo3bqxbAdvniGbMmFEHpAAAAAAAJHkwOn36dJkzZ44MHTpUUqVK5dhfoUIFOXz4cGKfDgAAAADggRK98o9qZlS2bNl4+319ffXiqQAAAACQknlbuzo25WZG8+fPLwcOHIi3f+PGjVKsWLGkGhcAAAAAwMISnRlV80V79OghkZGRem3RX375RZYsWSITJkyQuXPnJs8oAQAAAACeHYx27dpV/P395Z133pE7d+5I69atdVfdDz/8UFq1apU8owQAAAAAg1i9i22KDUaVNm3a6E0Fo7du3ZKgoKCkHxkAAAAAwLIeKRhVLl++LCdOnHB8cpAtW7akHBcAAAAAwMIS3cDo5s2b0q5dO12aW7NmTb2pr9u2bSsRERHJM0oAAAAAMIiXG21W5v0oc0Z//vlnWb9+vVy/fl1v69atk71798prr72WPKMEAAAAAHh2ma4KPDdt2iTVqlVz7GvQoIHMmTNHGjZsmNTjAwAAAABDedPAyD0zo1myZJHAwMB4+9W+TJkyJdW4AAAAAAAWluhgVC3potYavXTpkmOf+nrgwIEybNiwpB4fAAAAAMBTy3TLli3rstbOqVOnJE+ePHpTwsLCxNfXV65cucK8UQAAAAApGlW6bhSMNmvWLPlHAgAAAADwGAkKRkeMGJH8IwEAAAAAeIxEd9MFAAAAACtznqIINwpGY2NjZerUqbJs2TI9V/TevXsux8PDw5NyfAAAAAAAC0p0N91Ro0bJ+++/L6+88opERETozrotWrQQb29vGTlyZPKMEgAAAADg2cHo4sWLZc6cOdK/f39JnTq1vPrqqzJ37lwZPny4/PTTT8kzSgAAAAAwiKrSdZfNyhIdjKo1RUuVKqW/DggI0NlRpUmTJrJ+/fqkHyEAAAAAwHISHYzmzp1bLl68qL9+8sknZfPmzfrrPXv26LVGAQAAACAl8/bycpvNyhIdjDZv3ly2bt2qv37rrbdk2LBhUqhQIWnfvr107tw5OcYIAAAAAPD0brrvvvuu42vVxChv3ryya9cuHZA+//zzST0+AAAAAIAFJTozer9KlSrpjroVK1aU8ePHJ82oAAAAAMAkZjct8qKBUeKoeaSqZBcAAAAAAMOCUQAAAAAAkm3OKAAAAABYmZfV62PdBJlRAAAAAID7ZkZVk6J/c+XKlaQYDwAAAADAAyQ4GP3111//85waNWo87ngAJFAG/zRmDwFIVsXqDzB7CECyurbnI7OHAOAhKB91s2B0+/btyTsSAAAAAIDHoIERAAAAADihgZExyEADAAAAAAxHMAoAAAAAMBxlugAAAADgxJsqXUOQGQUAAAAApIxg9Pvvv5e2bdtK5cqV5fz583rfZ599Jj/88ENSjw8AAAAAYEGJDkZXrFghDRo0EH9/f732aFRUlN4fEREh48ePT44xAgAAAIChZbrusllZooPRsWPHyqxZs2TOnDmSJk0ax/6qVavK/v37k3p8AAAAAAALSnQweuLECalRo0a8/YGBgXL9+vWkGhcAAAAAwMIS3U03e/bs8vvvv0u+fPlc9qv5ogUKFEjKsQEAAACA4by8LF4fm1Izo926dZPevXvLzz//rP8jXbhwQRYvXiwDBgyQN954I3lGCQAAAADw7MzokCFDJC4uTurWrSt37tzRJbu+vr46GH3rrbeSZ5QAAAAAYBCrNw5KscGoyoYOHTpUBg4cqMt1b926JcWLF5eAgIDkGSEAAAAAwHISHYza+fj46CAUAAAAAIBkD0Zr1679rxN6t23bluhBAAAAAIC7oH+RmwajZcqUcbkfHR0tBw4ckN9++006dOiQlGMDAAAAAFhUooPRqVOnPnD/yJEj9fxRAAAAAACSfGmXh2nbtq3MmzcvqZ4OAAAAAEzh7eXlNpuVJVkwunv3bvHz80uqpwMAAAAAWFiiy3RbtGjhct9ms8nFixdl7969MmzYsKQcGwAAAADAohIdjAYGBrrc9/b2liJFisjo0aPl2WefTcqxAQAAAEDKLR9F0gWjsbGx0qlTJylVqpRkypQpMQ8FAAAAAODRgv5UqVLp7Of169cT8zAAAAAASDFU3yB32aws0RnokiVLyunTp5NnNAAAAAAAj5DoYHTs2LEyYMAAWbdunW5cdOPGDZcNAAAAAIAkmzOqGhT1799fGjdurO83bdpUvJzyxqqrrrqv5pUCAAAAQEpl9fU9U1wwOmrUKHn99ddl+/btyTsiAAAAAIDlJTgYVZlPpWbNmsk5HgAAAACAB0jU0i7OZbkAAAAAYEWEPW4YjBYuXPg/A9Lw8PDHHRMAAAAAwOISFYyqeaOBgYHJNxoAAAAAgEdIVDDaqlUrCQoKSr7RAAAAAIDJvCnTda91RpkvCgAAAAAwrZsuAAAAAFgZ64y6WTAaFxeXvCMBAAAAAHiMBJfpAgAAAABgSgMjAAAAALA6qnSNQWYUAAAAAGA4glEAAAAAgOEo0wUAAAAAJ6wzagwyowAAAAAAwxGMAgAAAAAMR5kuAAAAADjxEup0jUBmFAAAAABgODKjAAAAAOCEBkbGIDMKAAAAADAcwSgAAAAAwHCU6QIAAACAE8p0jUFmFAAAAABgOIJRAAAAAIDhKNMFAAAAACdeXtTpGoHMKAAAAADAcASjAAAAAADDUaYLAAAAAE7opmsMMqMAAAAAAMORGQUAAAAAJ/QvMgaZUQAAAACA4QhGAQAAAACGo0wXAAAAAJx4U6drCDKjAAAAAADPDUZjYmLk22+/lU8++URu3ryp9124cEFu3bpl9tAAAAAAAFYs0z179qw0bNhQwsLCJCoqSurXry/p06eXiRMn6vuzZs0ye4gAAAAAPATrjHpQZrR3795SoUIFuXbtmvj7+zv2N2/eXLZu3Wrq2AAAAAAAFs2Mfv/997Jr1y7x8fFx2Z8vXz45f/68aeMCAAAAAFg4GI2Li5PY2Nh4+8+dO6fLdQEAAADAKDTT9aAy3WeffVY++OADx30vLy/duGjEiBHSuHFjU8cGAAAAALBoZnTKlCnSoEEDKV68uERGRkrr1q3l1KlTkjVrVlmyZInZwwMAAADgQbyF1KjHBKO5c+eWgwcPytKlS/Wtyop26dJF2rRp49LQCAAAAABgDW4RjO7cuVOqVKmig0+1Oa89qo7VqFHD1PEBAAAAACw4Z7R27doSHh4eb39ERIQ+BgAAAABGNjByl83K3CIYtdlsumnR/a5evSrp0qUzZUwAAAAAAIuW6bZo0ULfqkC0Y8eO4uvr6zimlno5dOiQLt8FAAAAAFiLqcFoYGCgIzOq1hN1blbk4+MjlSpVkm7dupk4QgAAAACextvi5bHuwtRgdP78+fo2X758MmDAAEpyAQAAAMBDuEU33REjRujbK1euyIkTJ/TXRYoUkWzZspk8MgAAAACAZYPRO3fuSM+ePWXRokUSFxen96VKlUrat28v06dPl7Rp05o9RAAAAAAewtvqbWzdhFt00+3bt6/s2LFD1q5dK9evX9fb6tWr9b7+/fubPTwAAAAAgBUzoytWrJDly5dLrVq1HPsaN26sGxq9/PLLMnPmTFPHBwAAAMBzkBj1oMyoKtMNDg6Otz8oKEgfAwAAAABYi1sEo5UrV9ZNjCIjIx377t69K6NGjdLHAAAAAADW4hZluh9++KE0aNBAcufOLaVLl9b7Dh48KH5+frJp0yazh4eH2Ld3jyyY96kcO/qb7oQ8ddoMqVO3ntnDAh7Z3FkfyaezP3bZlydfflm6cr1cvHBeWjSp/8DHjZ34vtSt39CgUQIPV7Xck9K3fT0pVzyP5MgWKC/3nS1rvzvkcs6wN56TTs2rSMb0/rL74GnpNX6p/BF2RR+rXr6QbJ7b+4HPXa3NJNl3NEwK5Q2S6UNbSdEC2SUwwF8uXomQpRv2yrjZ30hMzD9NCAF38umcT2Trls0SGnpafP38pEyZstKn3wDJl7+A2UODG6OBkQcFoyVLlpRTp07J4sWL5fjx43rfq6++Km3atNHzRuGe7t69o5fgadaipfTr3dPs4QBJosCTBWXazE8d91Ol+ufPZFBwdlm3eYfLuatWfiVfLJonlatWN3ycwIOk8/eVwyfPy6LVu2Xp+93jHe/fsZ68+WpN6Tb8Mzlz/qoMf7OJrJ3RQ8q2HCtR92Lkp4OnJV+9EJfHqHNqP1NEB6JKdEysLF73ixw4/qdE3LwjpQrnlhnDXhVvby8Z8dFaw75XIKH27vlFXnm1jZQoVUpiY2Jl+ofvy+vdusjKNetZsQEwmVsEo4r6Y9CtWzezh4FEqFa9pt4AK1HLSmXJmi1B+3ds/1bq1G8oadOmM3CEwMNt/vGo3h6mR+vaMnHOJln33WF9v+uwRXL22wnStHZp+WrTPh1o/nX1puP81Km9pUmtp2Tml//7IEYFsWqzC7t4TWpUKCRVyz6ZbN8X8Dhmzv7fB4zK6HHvSu3qleXY0SNSvsLTpo0LgJvMGVUuXLggy5Ytk48++kimTZvmsgGAUf4MC5Pnn60pLZ9/VkYMHSiXLl544HnHjx6RUyeOy/PNWho+RuBR5MuVRZfubvv5nwok5catSNnz2xmp+FS+Bz6mSc2nJEtgOvls9U8Pfd4CT2SV+lWKyff7fk+WcQNJ7dbNfz5wyRAYaPZQ4MZUla67bI/j3XffFS8vL+nTp49jn+rT06NHD8mSJYsEBARIy5Yt5a+//nJ5XFhYmDz33HM6Yaiayg4cOFBiYmLEkpnRBQsWyGuvvSY+Pj76h6J+YHbq6169epk6PgCeoUSpp+SdUeMkb9788vffV/T80Te6tJPPv1oj6dK5Zj/Xrl6h5xs9VbqsaeMFEiN71gz69nL4/zKf+v7VmxKc5Z9j9+vQrLJs2X1Mzl++Hu/Y9gX9pEzRJ8TPN43MXf6DjJ65PplGDiSduLg4mTRxvJQpW04KFSps9nCAZLVnzx755JNP5KmnnnLZ37dvX1m/fr189dVXEhgYKD179pQWLVrIjz/+qI/HxsbqQDR79uyya9cuuXjxorRv317SpEkj48ePt15mdNiwYTJ8+HCJiIiQM2fOSGhoqGM7ffr0vz42KipKbty44bKpfQCQWJWr1tCNiAoWLiKVqlST96fPkpu3bsrWLRtdzlOfKG7esJ6sKCwtV1BGqV+5mCxctfuBx9sNnieVW0+UDiHzpVH1EtK3fV3Dxwgk1vixo+SPU6dk0ntTzR4KkKxu3bql++/MmTNHMmXK5Niv4q1PP/1U3n//falTp46UL19e5s+fr4POn376pwpm8+bNcvToUfn888+lTJky0qhRIxkzZozMmDFD7t27Z71gVK0l2qpVK/H2TvxwJkyYoCN6523yxAnJMk4AniV9+gySJ08+OffnWZf927/dLJGRd6VRkxdMGxuQWJf+vqFvgzKnd9kflCW9/HX1n2PO2r1QSa5G3JZ1O1y78dqd++u6HD99SZZt3CfvTFsjQ19rrJsYAe5q/NjRsnPHdzJn/kIJzp7d7OHAzXm70fYoVBmuym7Wq+e60sW+ffskOjraZX/RokUlT548snv3Px8+qttSpUpJcHCw4xy18olK+h05ckQsF4x26dJFp4kfRUhIiI7wnbeBg107AQLAo7hz57acOxcmWe9rXKRKdKvXrCOZMmU2bWxAYqmmQ2oZltoVizj2pU/nJ0+XzCc/HzoT7/z2TSvJF+t+SdByLSoITZM6FcEo3JLNZtOB6LatW2TOvIWSO/cTZg8JSJSoRFaCfvnll7J//36dtLvfpUuX9NTIjBkzuuxXgac6Zj/HORC1H7cfs9ycUfWDatKkiWzcuFFH4aoe2ZlKIz+Mr6+v3pxFJv3cWjzAndu39eRmu/PnzsnxY8d0djpHzpymjg14FNOmTpJqNWpLjhw55cqVy3rd0VTeqaR+w+cc5/wZdlYO7N8rU6bNMnWswIOk8/eRJ5/I5tK06KnCueTajTvy56VrMuOL7TK4a0P5PeyKDk5HvPmcDlDXbD/o8jy1niks+XNnlflf74r3Gq0aVdBdd3/7/YJeDqZ88Twy5q2msnzzPtYZhVsaP2aUbPhmnXww/WNJlzad/H3ln3V1A9Kn12vaAw/i3MPGHWKlUaNGuewbMWKEjBw5Mt65f/75p/Tu3Vu2bNmSIq5vtwlGN23apNesVO5vYAT3dOTIb9K1U3vH/fcm/fPpS9MXmsuY8e+aODLg0Vz56y8ZETJAIiKuS8ZMmaV0mXIyZ+ESlwzoutUrJSg4WCpWrmrqWIEHKVc8r2ye29txf9KAf+Y1f7bmJ+k+4nOZsuBbSevvKx+986pkTO8vuw78IU17fKyDSmcdm1WR3Qf+kJNnXLsrKjGxcdKvY30plDdI/xsddjFcZi7dKdM/32bAdwgk3rKlS/Rtl47tXPaPHjtBXmjewqRRAQmnKkH79evnsu/+ZJxzGe7ly5elXLlyjn2qIdHOnTv1qiUq5lLzPq9fv+6SHVXddFXDIkXd/vLLLy7Pa++2az8nqXjZVO2CydSk2qlTp0rHjh2T5PnIjMIT3ImKNXsIQLLKVe1/QRVgRdf2fGT2EIBk5+cWqa/EW7j3T3EXHSokvLT85s2bcvasa6+LTp066XmhgwcPlieeeEKyZcsmS5Ys0Uu6KCdOnNDH1VzRSpUqyYYNG3TVquqiq5Z1UWbPnq2Xd1GB7sMC4UfhFpeH+oaqViXLAAAAAMB8KbU2M3369FKyZEmXfWp5OrV8pn2/6tejMq2ZM2eWDBkyyFtvvSWVK1fWgajy7LPPSvHixaVdu3YyadIkPU/0nXfe0U2RkjIQdZsGRqquefr06WYPAwAAAAAsberUqTrzqTKjNWrU0KW3K1eudBxPlSqVrFu3Tt+qILVt27Z6ndHRo0cn+Vjcoky3efPmsm3bNh2xlyhRIl4DI+cfTkJQpgtPQJkurI4yXVgdZbrwBCm1THeRG5Xptk9EmW5K4xaXh5o826IFE8gBAAAAmM+bJqqeE4zOnz/f7CEAAAAAADwtGLW7cuWK7uakqGVeVKcnAAAAAID1uEUDo9u3b0vnzp0lR44cehKt2nLmzKk7Pd25c8fs4QEAAADwIF5utFmZWwSjqrXwjh07ZO3atXoBVrWtXr1a7+vfv7/ZwwMAAAAAWLFMd8WKFbJ8+XKpVauWY1/jxo3F399fXn75ZZk5c6ap4wMAAADgOehf5EGZUVWKGxwcHG9/UFAQZboAAAAAYEFuEYyqxVRHjBghkZGRjn13796VUaNG6WMAAAAAAGtxizLdDz74QBo2bCi5c+eW0qVL630HDx4UPz8/2bRpk9nDAwAAAOBBvKjT9ZxgtFSpUnLq1ClZvHixHD9+XO979dVXpU2bNnreKAAAAADAWkwPRqOjo6Vo0aKybt066datm9nDAQAAAAB4QjCaJk0al7miAAAAACCe3ljHA7jFz7lHjx4yceJEiYmJMXsoAAAAAABPyIwqe/bska1bt8rmzZv1/NF06dK5HF+5cqVpYwMAAAAAWDQYzZgxo7Rs2dLsYQAAAAAA3XQ9IRiNi4uTyZMny8mTJ+XevXtSp04dGTlyJB10AQAAAMDiTJ0zOm7cOHn77bclICBAcuXKJdOmTdPzRwEAAADALF5utFmZqcHookWL5OOPP5ZNmzbJqlWrZO3atXqtUZUxBQAAAABYl6nBaFhYmDRu3Nhxv169ero++8KFC2YOCwAAAABg5TmjaikXPz+/eOuORkdHmzYmAAAAAJ6NBkYeEIzabDbp2LGj+Pr6OvZFRkbK66+/7rK8C0u7AAAAAIC1mBqMdujQId6+tm3bmjIWAAAAAICHBKPz58838+UBAAAAwL0a63gQfs4AAAAAAMMRjAIAAAAAPKtMFwAAAADcDd10jUFmFAAAAABgODKjAAAAAOCEvKgxyIwCAAAAAAxHMAoAAAAAMBxlugAAAADghP5FxiAzCgAAAAAwHMEoAAAAAMBwlOkCAAAAgBNv+ukagswoAAAAAMBwBKMAAAAAAMNRpgsAAAAATuimawwyowAAAAAAw5EZBQAAAAAnXjQwMgSZUQAAAACA4QhGAQAAAACGo0wXAAAAAJzQwMgYZEYBAAAAAIYjGAUAAAAAGI4yXQAAAABw4k03XUOQGQUAAAAAGI5gFAAAAABgOMp0AQAAAMAJ3XSNQWYUAAAAAGA4MqMAAAAA4ITMqDHIjAIAAAAADEcwCgAAAAAwHGW6AAAAAODEi3VGDUFmFAAAAABgOIJRAAAAAIDhKNMFAAAAACfeVOkagswoAAAAAMBwBKMAAAAAAMNRpgsAAAAATuimawwyowAAAAAAw5EZBQAAAAAnXiRGDUFmFAAAAABgOIJRAAAAAIDhKNMFAAAAACc0MDIGmVEAAAAAgOEIRgEAAAAAhqNMFwAAAACceFOlawgyowAAAAAAwxGMAgAAAAAMR5kuAAAAADihm64xyIwCAAAAAAxHZhQAAAAAnHiRGDUEmVEAAAAAgOEIRgEAAAAAhqNMFwAAAACcUKVrDDKjAAAAAADDEYwCAAAAAAxHmS4AAAAAOPGmna4hyIwCAAAAAAxHMAoAAAAAMBxlukAK5ZeGz5JgbeG/fGT2EIBkdf1OtNlDAJJd9gxpJCWiSNcYvJsFAAAAABiOzCgAAAAAOCM1aggyowAAAAAAwxGMAgAAAAAMR5kuAAAAADjxok7XEGRGAQAAAACGIxgFAAAAABiOMl0AAAAAcOJFla4hyIwCAAAAAAxHMAoAAAAAMBxlugAAAADghCpdY5AZBQAAAAAYjswoAAAAADgjNWoIMqMAAAAAAMMRjAIAAAAADEeZLgAAAAA48aJO1xBkRgEAAAAAhiMYBQAAAAAYjjJdAAAAAHDiRZWuIciMAgAAAAAMRzAKAAAAADAcZboAAAAA4IQqXWOQGQUAAAAAGI7MKAAAAAA4IzVqCDKjAAAAAADDEYwCAAAAAAxHmS4AAAAAOPGiTtcQZEYBAAAAAIYjGAUAAAAAGI4yXQAAAABw4kWVriHIjAIAAAAADEcwCgAAAAAwHGW6AAAAAOCEKl1jkBkFAAAAABiOzCgAAAAAOCM1aggyowAAAAAAwxGMAgAAAAAMR5kuAAAAADjxok7XEGRGAQAAAACeF4wWKFBArl69Gm//9evX9TEAAAAAwH+bMGGCPP3005I+fXoJCgqSZs2ayYkTJ1zOiYyMlB49ekiWLFkkICBAWrZsKX/99ZfLOWFhYfLcc89J2rRp9fMMHDhQYmJixHLB6JkzZyQ2Njbe/qioKDl//rwpYwIAAADguby83GdLjB07duhA86effpItW7ZIdHS0PPvss3L79m3HOX379pW1a9fKV199pc+/cOGCtGjRwnFcxWYqEL13757s2rVLFi5cKAsWLJDhw4dLUvOy2Ww2McGaNWv0rYrW1TcYGBjo8gPYunWr/gHeH8knRGTSB+2A24mLM+VXFzCMV2L/BQZSmIi70WYPAUh22TOkkZTo8Llb4i5K5Q545MdeuXJFZzZV0FmjRg2JiIiQbNmyyRdffCEvvviiPuf48eNSrFgx2b17t1SqVEk2bNggTZo00UFqcHCwPmfWrFkyePBg/Xw+Pj4pv4GRCkLtbzY6dOjgcixNmjSSL18+mTJlikmjAwAAAICULSIiQt9mzpxZ3+7bt09nS+vVq+c4p2jRopInTx5HMKpuS5Uq5QhElQYNGsgbb7whR44ckbJly6b8YDQuLk7f5s+fX/bs2SNZs2Y1aygAAAAA4OBOtTlRUVF6c+br66u3/4q3+vTpI1WrVpWSJUvqfZcuXdKZzYwZM7qcqwJPdcx+jnMgaj9uP2apOaOhoaEEogAAAADwkKZEakqj86b2/Rc1d/S3336TL7/8UtyV6cFor169ZNq0afH2f/TRRzqSBwAAAADDU6NusoWEhOhyW+dN7fs3PXv2lHXr1sn27dsld+7cjv3Zs2fXjYnUyiXOVDdddcx+zv3dde337edYJhhdsWKFTh3fr0qVKrJ8+XJTxgQAAAAA7sDX11cyZMjgsj2sRFf1plWB6Ndffy3btm3TUyKdlS9fXvfnUc1i7VTDWLWUS+XKlfV9dXv48GG5fPmy4xzVWFa9bvHixZP0ezNtzqidWmPUuZOunfpm//77b1PGBAAAAAApTY8ePXSn3NWrV+u1Ru1zPFW85e/vr2+7dOki/fr1002NVMz11ltv6QBUNS9S1FIwKuhs166dTJo0ST/HO++8o5/7v+apprjMaMGCBWXjxo3x9quWwgUKFDBlTAAAAAA8l5cb/S8xZs6cqct4a9WqJTly5HBsS5cudZwzdepUvXRLy5Yt9XIvqvR25cqVjuOpUqXSJb7qVgWpbdu2lfbt28vo0aPFMuuM2s2bN0+nkgcOHCh16tTR+1TaWC3r8sEHH0i3bt0S/ZysMwpPwDqjsDrWGYXVsc4oPEFKXWf0yPnb4i5K5EonVmV6mW7nzp11q+Jx48bJmDFj9D61xqiK6lUEDgAAAACwHtMzo86uXLmia5kDAgIe63nIjMITkBmF1ZEZhdWRGYUnSKmZ0aMX3CczWjwnmVFDZMuWzewhAAAAAAA8JRhVS7gsW7ZMtxRW6944279/v2njAgAAAAAkD9O76U6bNk06deokwcHB8uuvv8ozzzwjWbJkkdOnT0ujRo3MHh4AAAAAD+PlRpuVmR6MfvzxxzJ79myZPn26+Pj4yKBBg/Siqr169dJtiQEAAAAA1mN6MKpKc6tUqaK/Vs2Lbt68qb9Wi6wuWbLE5NEBAAAA8Dhmp0O9PCM1anowqhZZDQ8P11/nyZNHfvrpJ/11aGiouFGjXwAAAACAlYLROnXqyJo1a/TXau5o3759pX79+vLKK69I8+bNzR4eAAAAAMCK64zGxcXpLXXqfxr7fvnll7Jr1y4pVKiQvPbaa3oeaWKxzig8AeuMwupYZxRWxzqj8AQpdZ3R4xfviLsomiOtWJWpwWhMTIyMHz9eOnfuLLlz506y5yUYhScgGIXVEYzC6ghG4QkIRh9fUQsHo6aW6aps6KRJk3RQCgAAAADwHKbPGa1bt67s2LHD7GEAAAAAgKaKc9xls7J/JmqaqFGjRjJkyBA5fPiwlC9fXtKlS+dyvGnTpqaNDQAAAABg0QZG3t7e/zpfKDY2NtHPyZxReALmjMLqmDMKq2POKDxBSp0zeuKS+8wZLZLdunNGTc+Mqk66AAAAAOAu+DjUQ+aMLlq0SKKiouLtv3fvnj4GAAAAALAe08t0U6VKJRcvXpSgoCCX/VevXtX7KNMFHowyXVgdZbqwOsp04QlSapnuyb/cp0y3cLB1y3RNz4yqWPhBbzjOnTsngYGBpowJAAAAAGDROaNly5bVQaja1PIuas1RO5UNDQ0NlYYNG5o1PAAAAACAFYPRZs2a6dsDBw5IgwYNJCAgwHHMx8dH8uXLJy1btjRreAAAAAA8lBctjKwdjI4YMULfqqDzlVdeET8/P7OGAgAAAADwtDmjHTp0kMjISJk7d66EhIRIeHi43r9//345f/682cMDAAAAAFhxndFDhw5JvXr1dLOiM2fOSLdu3SRz5syycuVKCQsLY3kXAAAAAIaiobuHZEb79u0rHTt2lFOnTrmU6jZu3Fh27txp6tgAAAAAABbNjO7du1dmz54db3+uXLnk0qVLpowJAAAAAGDxYNTX11du3LgRb//JkyclW7ZspowJAAAAgOeiStdDynSbNm0qo0ePlujoaH1frTuq5ooOHjyYpV0AAAAAwKJMD0anTJkit27dkqCgILl7967UrFlTChYsKOnTp5dx48aZPTwAAAAAnpgadZfNwrxsNptN3MAPP/ygO+uqwLRcuXK6w+6jioxJ0qEBbikuzi1+dYFkoyplACuLuPtPVRhgZdkzpJGU6I8rd8VdPJnNX6zKbYLRpEQwCk9AMAqrIxiF1RGMwhMQjD6+Jy0cjJrawCguLk4WLFig1xRVa4yqNx758+eXF198Udq1a8cbETf36ZxPZOuWzRIaelp8/fykTJmy0qffAMmXv4DZQwMeyb69e2TRgk/l6NEj8veVK/L+Bx9J7bquVRqnT/8hH059T/bv3SMxsbFSoMCT8t7UaZIjR07Txg08qkbP1pGLF87H2/9yq9by9jsjTBkT8DhiY2NlweyPZfPGdRJ+9W/JmjWbNGzSTNp3ec3xvrLm0yUf+NjXe/WTV9t1NnjEcFdeVq+P9fRgVCVkVfOib775RkqXLi2lSpXS+44dO6bXHVUB6qpVq8waHhJg755f5JVX20iJUqUkNiZWpn/4vrzerYusXLNe0qZNa/bwgERT89YLFy4qLzRvKf37vBXv+J9/hknn9q2lWYsX5Y0335J0AQHyx++/i6+PrynjBR7X4i+XS1xcrOP+76dOyevdOkn9ZxuaOi7gUX2x6FNZvWKphIwcJ/kKFJQTx47Iu6Pf0X+vX2zVVp+zcsN3Lo/5edf3MmnscKlZu75JowY8l2nBqMqI7ty5U7Zu3Sq1a9d2ObZt2zZp1qyZLFq0SNq3b2/WEPEfZs7+1OX+6HHvSu3qleXY0SNSvsLTpo0LeFTVqtfQ28N8NO0DqVa9pvTpN9Cx74kn8hg0OiDpZc6c2eX+vLmz9TVd4elnTBsT8DiOHDogVWvWlsrVaur7OXLmkq2bvpHjRw47zsmSNavLY37cuV3Kln9GcuZ+wvDxAp7OtG66S5YskbfffjteIKrUqVNHhgwZIosXLzZlbHg0t27e1LcZAgPNHgqQLNMKftj5neTJm0/efK2L1KlZRdq1flm2b/3W7KEBSSI6+p58s26NrgxgmgxSqhJPlZH9e36WP8+e0fd/P3lcDh/cLxWrVH/g+aqUd/cPO6XxCy0MHincnfoz6C6blZkWjKrOuQ0bPrwMqFGjRnLw4EFDx4THe6M+aeJ4KVO2nBQqVNjs4QBJLjz8qty5c0fmz5sjVapWl5mffCq169ST/n3f0iXrQEq3beu3cvPmTWnarLnZQwEeWZsOXaVO/UbS7qXnpU6lMtK17UvyYqt2Ur9Rkweev3H9GkmbLq3UqP3oqzgASIFluuHh4RIcHPzQ4+rYtWvX/vN5oqKi9ObMlspXfH2Zw2Wk8WNHyR+nTsmCz74weyhAsn3gotSqVUfatu+ovy5StJgcPPirLP/qS8oakeKtWrlCqlarIUFBD/+3GXB327/dKFs2rpNhYyfqOaMqM/rR+xMla7YgadjkhXjnb1jztdRr2IT3jYCnZUZVt7PUqR8eC6dKlUpiYv57jZYJEyZIYGCgyzZ54oQkHi3+zfixo2Xnju9kzvyFEpw9u9nDAZJFpkyZ9N+sAk8WdNlfIP+TcuniRdPGBSSFCxfOy88/7ZLmLV80eyjAY5n54RSdHa37bGN5smBhadC4qbz0antZvGBuvHMP/rpPws6GShNKdPEAXm60WZmp3XRV19yHfRJ1f7bzYUJCQqRfv36uz52KT7eM+m84YdwY2bZ1i3y64DPJzcR/WFiaND5SvERJOXsm1GX/2bNnWNYFKd7qr1dK5sxZpHqNWmYPBXgsUVGR4uXt+vbd29tb4mz/VLc4+2b1SilSrLgULFzUwBECcItgtEOHDv95TkI66apg9v6ANvK/E6pIAuPHjJIN36yTD6Z/LOnSptPrMioB6dOLn5+f2cMDEu3OndvyZ1iY4/758+fkxPFjuimXCjg7dOoigwf0k3LlK0iFZyrKrh++l507tsuceYtMHTfwuCXoa1atlOdfaPavFUtASlClWi35fP4cCc6eQ5fpnjpxTJZ9sUgaN3WdC3371i35butmebPPANPGCjdn9ZSkm/CyqfSWxRCMGqN0iSIP3D967AR5oTklL8ktLs5yv7qm27vnZ+nWOf4HZc83baaXLlJWfb1CL39x+a9Lkjdffnn9zbekdp26JozW+ujoaoxdP/6gO0SvXrdRX9MwTsTdaLOHYDl3bt+WT2dNl++/2yrXroVL1qzZpG6DxtKh6xuSJk0ax3lrVn6l55Ku3LhdAgLSmzpmq8ue4X8/95TkzNVIcRf5slg3yUMwCqRQBKOwOoJRWB3BKDwBwejjy2fhYJR6HAAAAABw4kWdrrW76QIAAAAAPBfBKAAAAADAs4LR6Oho6dy5s4SGui6VAAAAAABmUW0L3GWzMlODUdXVbMWKFWYOAQAAAADgiWW6zZo1k1WrVpk9DAAAAACAJ3XTLVSokIwePVp+/PFHKV++vKRLl87leK9evUwbGwAAAADPY/HqWLdh+jqj+fPn/9c15k6fPp3o52SdUXgC1hmF1bHOKKyOdUbhCVLqOqN/hkeJu3gis69YlemZUZoXAQAAAHAnfB7qIXNG7e7duycnTpyQmBjSmgAAAABgdaYHo3fu3JEuXbpI2rRppUSJEhIWFqb3v/XWW/Luu++aPTwAAAAAgBWD0ZCQEDl48KB899134ufn59hfr149Wbp0qaljAwAAAOCJvNxosy7T54yqZV1U0FmpUiWXZhUqS/rHH3+YOjYAAAAAgEUzo1euXJGgoKB4+2/fvk0nRQAAAACwKNOD0QoVKsj69esd9+0B6Ny5c6Vy5comjgwAAACAJ1IhibtsVmZ6me748eOlUaNGcvToUd1J98MPP9Rf79q1S3bs2GH28AAAAAAAVsyMVqtWTQ4cOKAD0VKlSsnmzZt12e7u3bulfPnyZg8PAAAAAJAMvGw2m00sJpKlSuEB4uIs96sLuKBvAKwu4m602UMAkl32DGkkJbpw/Z64i5wZfcSqTC/TVWJjY+Xrr7+WY8eO6fvFixeXF154QVKndovhAQAAAACslhk9cuSING3aVC5duiRFihTR+06ePCnZsmWTtWvXSsmSJRP9nGRG4QnIjMLqyIzC6siMwhOk1MzoxQj3yYzmCLRuZtT0YFR1zFWB58KFCyVTpkx637Vr16Rjx4562RfVyCixCEbhCQhGYXUEo7A6glF4AoLRx5eDYDT5+Pv7y969e6VEiRIu+3/77Td5+umn5e7du4l+ToJReAKCUVgdwSisjmAUnoBg9PHlsHAwano33cKFC8tff/0Vb//ly5elYMGCpowJAAAAgOfycqP/WZnpweiECROkV69esnz5cjl37pze1Nd9+vSRiRMnyo0bNxwbAAAAAMAaTC/T9fb2jleSZR+S8331teq6mxCU6cITUKYLq6NMF1ZHmS48QUot070U4T6/n9kDU+bPMCFMXztl+/btZg8BAAAAAP6Hz0M9IzOaHMiMwhOQGYXVkRmF1ZEZhSdIsZnRG+7z+5k9hf4MU0RmdOfOnf96vEaNGoaNBQAAAADggXNGH/RpeELniTojMwpPQGYUVkdmFFZHZhSeIKVm9f5yo8xocAr9GaaIbrrXrl1z2dSSLhs3btRrjG7evNns4QEAAAAArFimGxgYGG9f/fr1xcfHR/r16yf79u0zZVwAAAAAPBPFOR6SGX2Y4OBgOXHihNnDAAAAAABYMTN66NAhl/tqCuvFixfl3XfflTJlypg2LgAAAACAhYNRFXCqJhX391GqVKmSzJs3z7RxAQAAAPBMXiw06hnBaGhoaLzuutmyZRM/Pz/TxgQAAAAAsHgwmjdvXrOHAAAAAADwlAZGu3fvlnXr1rnsW7RokeTPn1+CgoKke/fuEhUVZdbwAAAAAHgqLzfaLMy0YHT06NFy5MgRx/3Dhw9Lly5dpF69ejJkyBBZu3atTJgwwazhAQAAAACsGIweOHBA6tat67j/5ZdfSsWKFWXOnDl6fdFp06bJsmXLzBoeAAAAAMCKc0avXbum1xK127FjhzRq1Mhx/+mnn5Y///zTpNEBAAAA8FQWr451G6ZlRlUgau+ke+/ePdm/f79ezsXu5s2bkiZNGrOGBwAAAACwYma0cePGem7oxIkTZdWqVZI2bVqpXr264/ihQ4fkySefNGt4AAAAADyUF6lRawejY8aMkRYtWkjNmjUlICBAFi5cKD4+Po7j8+bNk2effdas4QEAAAAAkpGXzWaziYkiIiJ0MJoqVSqX/eHh4Xq/c4CaUJExSThAwE3FxZn6qwskOy8+lobFRdyNNnsIQLLLniFlTru7ett9Aoos6UzLHyY707+zwMDAB+7PnDmz4WMBAAAAAC9aGFm7gREAAAAAwHMRjAIAAAAAPK9MFwAAAADcCW0LjEFmFAAAAABgOIJRAAAAAIDhCEYBAAAAAIYjGAUAAAAAGI4GRgAAAADghAZGxiAzCgAAAAAwHMEoAAAAAMBwlOkCAAAAgBMvoU7XCGRGAQAAAACGIxgFAAAAABiOMl0AAAAAcEI3XWOQGQUAAAAAGI5gFAAAAABgOMp0AQAAAMAJVbrGIDMKAAAAADAcmVEAAAAAcEZq1BBkRgEAAAAAhiMYBQAAAAAYjjJdAAAAAHDiRZ2uIciMAgAAAAAMRzAKAAAAADAcZboAAAAA4MSLKl1DkBkFAAAAABiOYBQAAAAAYDjKdAEAAADACVW6xiAzCgAAAAAwHJlRAAAAAHBGatQQZEYBAAAAAIYjGAUAAAAAGI4yXQAAAABw4kWdriHIjAIAAAAADEcwCgAAAAAwHGW6AAAAAODEiypdQ5AZBQAAAAAYjmAUAAAAAGA4L5vNZjP+ZWElUVFRMmHCBAkJCRFfX1+zhwMkOa5xeAKuc1gd1zjgfghG8dhu3LghgYGBEhERIRkyZDB7OECS4xqHJ+A6h9VxjQPuhzJdAAAAAIDhCEYBAAAAAIYjGAUAAAAAGI5gFI9NNQEYMWIEzQBgWVzj8ARc57A6rnHA/dDACAAAAABgODKjAAAAAADDEYwCAAAAAAxHMAoAj+jMmTPi5eUlBw4cMHsoAAAAKQ7BqAfo2LGjfsOstjRp0khwcLDUr19f5s2bJ3FxcQl+npEjR0qZMmXEKGq8q1atMuz1YJ3r3MfHRwoWLCijR4+WmJiYZHvNJ554Qi5evCglS5ZMtteAZzPjun6csTZr1szsYSCZXblyRd544w3JkyePbgSUPXt2adCggfz4449i9fdBCu+FgKRFMOohGjZsqN80q0zOhg0bpHbt2tK7d29p0qRJkr+piY6OTtLnAxJ7nZ86dUr69++v3zRMnjw52V4vVapU+o1Y6tSpk+01gIRe1/fu3TNlfPAsLVu2lF9//VUWLlwoJ0+elDVr1kitWrXk6tWrZg/tX38HjHwfpPBeCEgg1U0X1tahQwfbCy+8EG//1q1bVSdl25w5c/T9a9eu2bp06WLLmjWrLX369LbatWvbDhw4oI/Nnz9fn+u8qX2K+vrjjz+2Pf/887a0adPaRowYYYuJibF17tzZli9fPpufn5+tcOHCtg8++CDeGD799FNb8eLFbT4+Prbs2bPbevTooffnzZvX5bXUfSCx13n9+vVtlSpVsk2ZMsVWsmRJfX3mzp3b9sYbb9hu3rzpOO/MmTO2Jk2a2DJmzKjPUdfk+vXr9bHw8HBb69at9e+FupYLFixomzdvnj4WGhqqr89ff/3VFhsba8uVK5f+XXC2f/9+m5eXl36N//o9AxJzXduPjR071pYjRw7991Y5dOiQvq7U9Zo5c2Zbt27dXK53++PGjRtnCwoKsgUGBtpGjRpli46Otg0YMMCWKVMmfS3br3O7f3te9Xf//n8jtm/fro+FhYXZXnrpJf066rmbNm2qf3eQ8qi/X+q/7XfffffQc5z/Lt7/OPs1oW7V/XXr1tlKlSpl8/X1tVWsWNF2+PBhl+f6/vvvbdWqVdPXnPrb/dZbb9lu3brlOK7eG4wePdrWrl07/fdUXduP8z7IPlbeCwHGITPqwerUqSOlS5eWlStX6vsvvfSSXL58WX9iuG/fPilXrpzUrVtXwsPD5ZVXXtGfyJcoUUJ/sqg2tc9OfVLfvHlzOXz4sHTu3FmXveTOnVu++uorOXr0qAwfPlzefvttWbZsmeMxM2fOlB49ekj37t3149Snq6oETdmzZ4++nT9/vn4t+30gMfz9/fUn5d7e3jJt2jQ5cuSI/jR/27ZtMmjQIMd56jqMioqSnTt36mtx4sSJEhAQoI8NGzZMX8Pq9+LYsWP6us2aNWu811Kv8eqrr8oXX3zhsn/x4sVStWpVyZs373/+ngGJua6VrVu3yokTJ2TLli2ybt06uX37ti6ZzJQpk/67qf4Gf/vtt9KzZ0+X51C/AxcuXNDX/Pvvv6/XXlQZIvW4n3/+WV5//XV57bXX5Ny5c/r8/3reAQMGyMsvv+zIPqmtSpUqOjukHpc+fXr5/vvvdSmn+t1S55HJTXnUfzu1qbJR9TfzcQ0cOFCmTJmir6ls2bLJ888/78go/vHHH/o6UZnYQ4cOydKlS+WHH36Idy2/9957+r2Mytaqv9eP8z5I4b0QYDADA1+Y5GGfCCqvvPKKrVixYvrTxwwZMtgiIyNdjj/55JO2Tz75RH+tPuUrXbp0vOdQl1GfPn3+cxzqk76WLVs67ufMmdM2dOjQh56vnvfrr7/+z+cF7r/O4+LibFu2bNGftqtMz/2++uorW5YsWRz31SfzI0eOfODzqk+5O3XqlKAMgLpVWdCzZ8/q+/Zs6cyZM/X9hPyeAQm9rtWx4OBgW1RUlOP82bNn6+yjc/ZIZfm9vb1tly5dcjynyrCo69OuSJEiturVqzvuq4xOunTpbEuWLEnU897/b81nn32mn1uN3U6N19/f37Zp06Yk/VnBGMuXL9fXgsr0ValSxRYSEmI7ePDgI2VGv/zyS8c5V69e1dfF0qVL9X2VnezevbvLa6u/oeqau3v3rr6vruNmzZolyfsg+/PzXggwFplRD6f+zqnJ8QcPHpRbt25JlixZHJ98qi00NFR/OvlfKlSoEG/fjBkzpHz58vrTTvVcs2fPlrCwMH1MfeqoPpVXnzYCSUVlhtS15ufnJ40aNdKfWKtPqlUGR11ruXLl0hmadu3a6flNd+7c0Y/r1auXjB07VmcwVYZIfQpvpxp1fPnll7phhcqm7tq166Gvr84pVqyYIzu6Y8cOfa2rT9qVx/09g2d62HWtlCpVSjc2slPZe5XpSZcunWOfuq5VhkZlUO1UZkdl8+1UQxf1XM7zodV1qq7fxDzv/dQ1//vvv+vfO/v1njlzZomMjOSaT6FUplL9+60yeCpz+d133+ns4YIFCxL9XJUrV3Z8ra6LIkWK6GvNfu2o53T+W6my7OqaU38z/+39x6O8D7K/Ju+FAGPRdcPDqT/6+fPn1398c+TIof9RuV/GjBn/83mc36Ao6s27KttS5TfqHxv1RkQ13FDlX/YyMyCpqYYUquRJvTnPmTOnbiykmlWo8kMVVI4bN06/4VGlXl26dNFlgmnTppWuXbvqNznr16+XzZs3y4QJE/S1+9Zbb+k3/2fPnpVvvvlGl0KqNw2qpEqVhj1ImzZtdDA6ZMgQfaverKk3Nsrj/p7BMz3oun7Y396EUh1Fndm7jN6/L7GdRu+nrnn1RlyVq99PvTlHyqQ+GFHdaNWmSmPV31D1QZ7qWmv/kOOfpN6jN/NR144qFVcfFt5PdfJ93N+B+98H2V+T90KAsQhGPZiaM6TmJ/Tt21fPabh06ZJ+k5MvX74Hnq/eCMXGxiboudW8IDVf6M0333Tsc/5UUf1BVq+j5jupN1oPot4YJfT1APsbAftcGzs150e9oVZvBuxvkpzn6zgv06LmyaktJCRE5syZo4NR+5vmDh066K169ep6ntPDgtHWrVvLO++8o193+fLlMmvWLMcxlT34r98zICHX9cOozLzKJqk5nvY3xurvsbr2VdbpUSXkeR/0b4S65tVcv6CgIMmQIcMjvz7cW/HixR3Lj9g/ZFBzHMuWLau/fthazD/99JMjsLx27ZruzquuNfu1o+ZZJvTaf9z3QfbX5L0QYCzKdD2EajSg/sCeP39e9u/fL+PHj5cXXnhBZ4zat28v9erV05/aqTXiVGZIZZNUOeLQoUNl7969+jnUH0xVqqL+Ufn777//tXlBoUKF9OM2bdqk/3FRn5zeP/FelZmpAEE1llFLFqhxTZ8+3XHc/gdajVv9IwU8CvVGRn0qr66t06dPy2effeYSICp9+vTR16q6vtV1uH37dscbItVwYvXq1brUUDVAUiWT9mMPoq5b9eZDZV7VG4imTZs6jiXk9wx4HCozr7JW6oOT3377TV/L6kMVVZquSnGT83nVta9K3FXZrvo3Qv3eqcephl/q3xvVwEj9jqmsk8p22ZsjIeVQ0xtU05/PP/9c/7dW/z1Vc55Jkybp/8b2bF+lSpXk3Xff1VlHNV1BfUD3IGrNXPXvvLqmVFZVXSv2tWoHDx6s/z6qhkXqfYd6n6D+Ft/fwCip3gcpvBcCTGDwHFWYQE3ct7cFT506tS1btmy2evXq6bb9zg0sbty4odumq8n0adKksT3xxBO2Nm3a6Lb8iprQrybdq+Uv7m9nfv/kenVux44ddSt/db5aSmPIkCHxJv3PmjVLN7dQr6eWJlCvb7dmzRq9jIYaM+3M8TgNKt5//319fanmGA0aNLAtWrRIX7eqqYbSs2dP3aBCNYZRvx9qmYC///5bHxszZoxubqEeq5azUK9x+vTphzbqUFR7f7W/ffv28cbyX79nQEKv64cdS+jSLs5q1qxp6927t8s+9Xd36tSpCX7ey5cv62VnAgICXJrVXLx4Uf8uqKUy1O9YgQIF9GMjIiIe4ycDM6h/29W/5eXKldP/vqslTNS/4e+8847tzp07jvOOHj1qq1y5sv67WaZMGdvmzZsf2MBo7dq1thIlSuglTZ555hmXRkjKL7/84rimVEOtp556Si9J9LBr9HHfBym8FwKM5aX+z4wgGAAAAJ5HZcdVWarK9DFfHvBslOkCAAAAAAxHMAoAAAAAMBxlugAAAAAAw5EZBQAAAAAYjmAUAAAAAGA4glEAAAAAgOEIRgEAAAAAhiMYBQAAAAAYjmAUAJAoHTt2lGbNmjnu16pVS/r06WP4OL777jvx8vKS69evG/a9uus4AQBIiQhGAcACVNCkAh61+fj4SMGCBWX06NESExOT7K+9cuVKGTNmjFsGZvny5ZMPPvjAkNcCAACJkzqR5wMA3FTDhg1l/vz5EhUVJd9884306NFD0qRJIyEhIfHOvXfvng5ak0LmzJmT5HkAAIBnITMKABbh6+sr2bNnl7x588obb7wh9erVkzVr1riUm44bN05y5swpRYoU0fv//PNPefnllyVjxow6qHzhhRfkzJkzjueMjY2Vfv366eNZsmSRQYMGic1mc3nd+8t0VTA8ePBgeeKJJ/SYVJb2008/1c9bu3ZtfU6mTJl0hlSNS4mLi5MJEyZI/vz5xd/fX0qXLi3Lly93eR0VYBcuXFgfV8/jPM5Hob63Ll26OF5T/Uw+/PDDB547atQoyZYtm2TIkEFef/11HczbJWTsAAAgPjKjAGBRKjC6evWq4/7WrVt1MLVlyxZ9Pzo6Who0aCCVK1eW77//XlKnTi1jx47VGdZDhw7pzOmUKVNkwYIFMm/ePClWrJi+//XXX0udOnUe+rrt27eX3bt3y7Rp03RgFhoaKn///bcOTlesWCEtW7aUEydO6LGoMSoqmPv8889l1qxZUqhQIdm5c6e0bdtWB4A1a9bUQXOLFi10trd79+6yd+9e6d+//2P9fFQQmTt3bvnqq690oL1r1y793Dly5NABuvPPzc/PT5cYqwC4U6dO+nwV2Cdk7AAA4CFsAIAUr0OHDrYXXnhBfx0XF2fbsmWLzdfX1zZgwADH8eDgYFtUVJTjMZ999pmtSJEi+nw7ddzf39+2adMmfT9Hjhy2SZMmOY5HR0fbcufO7XgtpWbNmrbevXvrr0+cOKHSpvr1H2T79u36+LVr1xz7IiMjbWnTprXt2rXL5dwuXbrYXn31Vf11SEiIrXjx4i7HBw8eHO+57pc3b17b1KlTbQnVo0cPW8uWLR331c8tc+bMttu3bzv2zZw50xYQEGCLjY1N0Ngf9D0DAACbjcwoAFjEunXrJCAgQGc8VdavdevWMnLkSMfxUqVKucwTPXjwoPz++++SPn16l+eJjIyUP/74QyIiIuTixYtSsWJFxzGVPa1QoUK8Ul27AwcOSKpUqRKVEVRjuHPnjtSvX99lvyqFLVu2rP762LFjLuNQVEb3cc2YMUNnfcPCwuTu3bv6NcuUKeNyjsrupk2b1uV1b926pbO16va/xg4AAB6MYBQALELNo5w5c6YOONW8UBU4OkuXLp3LfRVIlS9fXhYvXhzvuVSJ6aOwl90mhhqHsn79esmVK5fLMTXnNLl8+eWXMmDAAF16rAJMFZRPnjxZfv75Z7cfOwAAVkAwCgAWoYJN1SwoocqVKydLly6VoKAgPX/zQdT8SRWc1ahRQ99XS8Xs27dPP/ZBVPZVZWV37NihGyjdz56ZVc2D7IoXL64DN5WdfFhGVc1XtTdjsvvpp5/kcfz4449SpUoVefPNNx37VEb4fiqDrLKm9kBbva7KQKs5sKrp03+NHQAAPBjddAHAQ7Vp00ayZs2qO+iqBkaq0ZBq0tOrVy85d+6cPqd3797y7rvvyqpVq+T48eM6cPu3NULVup4dOnSQzp0768fYn3PZsmX6uOr0q7roqpLiK1eu6MyiykiqDGXfvn1l4cKFOiDcv3+/TJ8+Xd9XVAfbU6dOycCBA3Xzoy+++EI3VkqI8+fP6/Jh5+3atWu62ZBqhLRp0yY5efKkDBs2TPbs2RPv8arkVnXdPXr0qO7oO2LECOnZs6d4e3snaOwAAODBCEYBwEOpeZCq82uePHl0p1qVfVRBl5ozas+Uqo617dq10wGmvZS1efPm//q8qlT4xRdf1IFr0aJFpVu3bnL79m19TJWyqmVShgwZIsHBwTqoU8aMGaODQdWZVo1DdfRVpa9quRRFjVF14lUBrprDqTrXjh8/PkHf53vvvafnbzpv6rlfe+01/X2/8sorej6q6jzsnCW1q1u3rg5cVXZYndu0aVOXubj/NXYAAPBgXqqL0UOOAQAAAACQLMiMAgAAAAAMRzAKAAAAADAcwSgAAAAAwHAEowAAAAAAwxGMAgAAAAAMRzAKAAAAADAcwSgAAAAAwHAEowAAAAAAwxGMAgAAAAAMRzAKAAAAADAcwSgAAAAAwHAEowAAAAAAMdr/AXtYOgBAOMFdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores: [0.75059102 0.75768322 0.75694855 0.76227085 0.76759314]\n",
      "Mean CV score: 0.7590173537277731\n",
      "Standard deviation: 0.005677893107213202\n"
     ]
    }
   ],
   "source": [
    "# using sklearn logistic regression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Define features\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in target and features\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check + ['Likely to recommend']).copy()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Create full pipeline including the model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        max_iter=1000,\n",
    "        solver='lbfgs',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Fit the pipeline\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Print model performance\n",
    "print(\"Model Performance:\\n\")\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Get and display feature coefficients\n",
    "coefficients = model_pipeline.named_steps['classifier'].coef_\n",
    "classes = model_pipeline.named_steps['classifier'].classes_\n",
    "\n",
    "print(\"\\nFeature Importance for each class:\")\n",
    "for idx, class_name in enumerate(classes):\n",
    "    print(f\"\\nClass: {class_name}\")\n",
    "    feat_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': coefficients[idx]\n",
    "    })\n",
    "    feat_importance = feat_importance.sort_values('Coefficient', key=abs, ascending=False)\n",
    "    print(feat_importance.head(10))  # Show top 10 most important features\n",
    "\n",
    "# Additional model evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cross-validation scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(model_pipeline, X, y, cv=5)\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())\n",
    "print(\"Standard deviation:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "\n",
      "Test Accuracy: 0.710401891252955\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Detract       0.25      0.49      0.33        92\n",
      "      Passive       0.44      0.57      0.50       355\n",
      "      Promote       0.93      0.76      0.84      1133\n",
      "Super Detract       0.74      0.78      0.76       112\n",
      "\n",
      "     accuracy                           0.71      1692\n",
      "    macro avg       0.59      0.65      0.61      1692\n",
      " weighted avg       0.78      0.71      0.73      1692\n",
      "\n",
      "\n",
      "Feature Importance for each class:\n",
      "\n",
      "Class: Detract\n",
      "                                              Feature  Coefficient\n",
      "20           iag_product_type_auto_Private Motor Line     1.140395\n",
      "1   iag_value_price_of_policy_reflects_scale11_scaled    -0.615165\n",
      "11                            iag_age_band_auto_25-34    -0.609203\n",
      "7                       iag_business_unit_ug_Consumer     0.591490\n",
      "9                               iag_age_band_auto_65+    -0.557882\n",
      "10                             iag_age_band_auto_0-24    -0.522350\n",
      "3   iag_value_price_of_policy_reflects_scale11_binned    -0.487972\n",
      "27                    iag_product_type_auto_EasyRider     0.448820\n",
      "22                       iag_product_type_auto_Wheels     0.441229\n",
      "18                          iag_tenure_band_enum_6-10    -0.402951\n",
      "\n",
      "Class: Passive\n",
      "                                              Feature  Coefficient\n",
      "2                 iag_trust_confidence_scale11_binned    -1.162693\n",
      "16                           iag_tenure_band_enum_30+    -0.766480\n",
      "27                    iag_product_type_auto_EasyRider     0.684025\n",
      "25                     iag_product_type_auto_Landlord    -0.495898\n",
      "3   iag_value_price_of_policy_reflects_scale11_binned     0.457829\n",
      "1   iag_value_price_of_policy_reflects_scale11_scaled     0.452120\n",
      "18                          iag_tenure_band_enum_6-10     0.405547\n",
      "11                            iag_age_band_auto_25-34     0.392020\n",
      "12                            iag_age_band_auto_35-44     0.387555\n",
      "22                       iag_product_type_auto_Wheels    -0.357238\n",
      "\n",
      "Class: Promote\n",
      "                                              Feature  Coefficient\n",
      "0                 iag_trust_confidence_scale11_scaled     0.849039\n",
      "2                 iag_trust_confidence_scale11_binned     0.606154\n",
      "7                       iag_business_unit_ug_Consumer    -0.580535\n",
      "25                     iag_product_type_auto_Landlord    -0.470741\n",
      "26                    iag_product_type_auto_Jetsetter    -0.457165\n",
      "18                          iag_tenure_band_enum_6-10     0.351727\n",
      "28                  iag_region_ug_Consumer Claims Ops     0.344432\n",
      "14                         iag_tenure_band_enum_11-20    -0.307967\n",
      "21              iag_product_type_auto_Homeowners Line    -0.307184\n",
      "3   iag_value_price_of_policy_reflects_scale11_binned    -0.236618\n",
      "\n",
      "Class: Super Detract\n",
      "                                     Feature  Coefficient\n",
      "0        iag_trust_confidence_scale11_scaled    -1.460632\n",
      "20  iag_product_type_auto_Private Motor Line    -0.926368\n",
      "27           iag_product_type_auto_EasyRider    -0.908836\n",
      "25            iag_product_type_auto_Landlord     0.687680\n",
      "26           iag_product_type_auto_Jetsetter     0.635112\n",
      "9                      iag_age_band_auto_65+     0.562939\n",
      "2        iag_trust_confidence_scale11_binned     0.551031\n",
      "16                  iag_tenure_band_enum_30+     0.535828\n",
      "15                  iag_tenure_band_enum_1-2     0.534248\n",
      "21     iag_product_type_auto_Homeowners Line     0.445895\n",
      "\n",
      "Confusion Matrix:\n",
      "                    Pred Detract  Pred Passive  Pred Promote  \\\n",
      "True Detract                  45            22             5   \n",
      "True Passive                  82           204            60   \n",
      "True Promote                  38           227           866   \n",
      "True Super Detract            15             6             4   \n",
      "\n",
      "                    Pred Super Detract  \n",
      "True Detract                        20  \n",
      "True Passive                         9  \n",
      "True Promote                         2  \n",
      "True Super Detract                  87  \n",
      "\n",
      "Original class distribution:\n",
      "Likely to recommend\n",
      "Promote          4529\n",
      "Passive          1419\n",
      "Super Detract     446\n",
      "Detract           371\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced class distribution:\n",
      "Likely to recommend\n",
      "Passive          4529\n",
      "Promote          4529\n",
      "Super Detract    4529\n",
      "Detract          4529\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:227: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores: [0.68321513 0.70330969 0.70136014 0.70490834 0.73447664]\n",
      "Mean CV score: 0.7054539887850153\n",
      "Standard deviation: 0.016483546374342767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class NumericFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Convert DataFrame to numpy array if necessary\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        self.scaler.fit(X_array)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Convert DataFrame to numpy array if necessary\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        \n",
    "        # Create binned features\n",
    "        trust_binned = pd.cut(X_array[:, 0], bins=self.trust_bins, labels=False)\n",
    "        price_binned = pd.cut(X_array[:, 1], bins=self.price_bins, labels=False)\n",
    "        \n",
    "        # Create interaction and polynomial features\n",
    "        trust_price_interaction = X_array[:, 0] * X_array[:, 1]\n",
    "        trust_squared = X_array[:, 0] ** 2\n",
    "        price_squared = X_array[:, 1] ** 2\n",
    "        \n",
    "        # Scale original features\n",
    "        X_scaled = self.scaler.transform(X_array)\n",
    "        \n",
    "        # Combine all features\n",
    "        return np.column_stack([\n",
    "            X_scaled,  # 2 columns\n",
    "            trust_binned.reshape(-1, 1),  # 1 column\n",
    "            price_binned.reshape(-1, 1),  # 1 column\n",
    "            trust_price_interaction.reshape(-1, 1),  # 1 column\n",
    "            trust_squared.reshape(-1, 1),  # 1 column\n",
    "            price_squared.reshape(-1, 1)  # 1 column\n",
    "        ])\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names=None):\n",
    "        if feature_names is None:\n",
    "            feature_names = ['trust', 'price']\n",
    "            \n",
    "        scaled_names = [f\"{name}_scaled\" for name in feature_names]\n",
    "        binned_names = [f\"{name}_binned\" for name in feature_names]\n",
    "        interaction_names = ['trust_price_interaction']\n",
    "        squared_names = [f\"{name}_squared\" for name in feature_names]\n",
    "        \n",
    "        return np.array(scaled_names + binned_names + interaction_names + squared_names)\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check + ['Likely to recommend']).copy()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = NumericFeatureTransformer()\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features)\n",
    ")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "numeric_feature_names = list(numeric_transformer.get_feature_names_out(numeric_features))\n",
    "categorical_feature_names = [\n",
    "    f\"{feat}_{val}\" for feat in categorical_features \n",
    "    for val in df_clean[feat].unique()[1:]\n",
    "]\n",
    "feature_names = numeric_feature_names + categorical_feature_names\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Fit the classifier\n",
    "classifier = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "classifier.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test_transformed)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Model Performance:\\n\")\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display feature importance\n",
    "print(\"\\nFeature Importance for each class:\")\n",
    "for idx, class_name in enumerate(classifier.classes_):\n",
    "    print(f\"\\nClass: {class_name}\")\n",
    "    feat_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Coefficient': classifier.coef_[idx]\n",
    "    })\n",
    "    feat_importance = feat_importance.sort_values('Coefficient', key=abs, ascending=False)\n",
    "    print(feat_importance.head(10))\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f'True {c}' for c in classifier.classes_],\n",
    "    columns=[f'Pred {c}' for c in classifier.classes_]\n",
    "))\n",
    "\n",
    "# Print class distributions\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())\n",
    "\n",
    "# Calculate cross-validation scores\n",
    "cv_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        solver='lbfgs',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv_scores = cross_val_score(cv_pipeline, X, y, cv=5)\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())\n",
    "print(\"Standard deviation:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "\n",
      "Test Accuracy: 0.7204491725768322\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Detract       0.27      0.45      0.34        92\n",
      "      Passive       0.46      0.65      0.54       355\n",
      "      Promote       0.93      0.76      0.84      1133\n",
      "Super Detract       0.75      0.79      0.77       112\n",
      "\n",
      "     accuracy                           0.72      1692\n",
      "    macro avg       0.60      0.66      0.62      1692\n",
      " weighted avg       0.78      0.72      0.74      1692\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                    Pred Detract  Pred Passive  Pred Promote  \\\n",
      "True Detract                  41            26             4   \n",
      "True Passive                  65           229            56   \n",
      "True Promote                  31           238           861   \n",
      "True Super Detract            14             6             4   \n",
      "\n",
      "                    Pred Super Detract  \n",
      "True Detract                        21  \n",
      "True Passive                         5  \n",
      "True Promote                         3  \n",
      "True Super Detract                  88  \n",
      "\n",
      "Original class distribution:\n",
      "Likely to recommend\n",
      "Promote          4529\n",
      "Passive          1419\n",
      "Super Detract     446\n",
      "Detract           371\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced class distribution:\n",
      "Likely to recommend\n",
      "Promote          4529\n",
      "Passive          4076\n",
      "Super Detract    3623\n",
      "Detract          3623\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "class EnhancedNumericTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        self.power_transformer.fit(X_array)\n",
    "        X_power = self.power_transformer.transform(X_array)\n",
    "        self.scaler.fit(X_power)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        X_power = self.power_transformer.transform(X_array)\n",
    "        X_scaled = self.scaler.transform(X_power)\n",
    "        \n",
    "        # Create binned features\n",
    "        trust_binned = pd.cut(X_array[:, 0], bins=self.trust_bins, labels=False)\n",
    "        price_binned = pd.cut(X_array[:, 1], bins=self.price_bins, labels=False)\n",
    "        \n",
    "        # Create interaction features\n",
    "        trust_price_interaction = X_scaled[:, 0] * X_scaled[:, 1]\n",
    "        trust_squared = X_scaled[:, 0] ** 2\n",
    "        price_squared = X_scaled[:, 1] ** 2\n",
    "        trust_cubed = X_scaled[:, 0] ** 3\n",
    "        price_cubed = X_scaled[:, 1] ** 3\n",
    "        \n",
    "        # Create threshold-based features\n",
    "        high_trust = (X_array[:, 0] > 8).astype(float)\n",
    "        high_price = (X_array[:, 1] > 7).astype(float)\n",
    "        low_trust = (X_array[:, 0] < 6).astype(float)\n",
    "        low_price = (X_array[:, 1] < 5).astype(float)\n",
    "        \n",
    "        # Scale all engineered features\n",
    "        engineered_features = np.column_stack([\n",
    "            trust_price_interaction,\n",
    "            trust_squared,\n",
    "            price_squared,\n",
    "            trust_cubed,\n",
    "            price_cubed,\n",
    "            high_trust,\n",
    "            high_price,\n",
    "            low_trust,\n",
    "            low_price\n",
    "        ])\n",
    "        engineered_scaler = StandardScaler()\n",
    "        engineered_scaled = engineered_scaler.fit_transform(engineered_features)\n",
    "        \n",
    "        return np.column_stack([\n",
    "            X_scaled,  # Original scaled features (2)\n",
    "            trust_binned.reshape(-1, 1),  # Binned features (2)\n",
    "            price_binned.reshape(-1, 1),\n",
    "            engineered_scaled  # Engineered features (9)\n",
    "        ])\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names=None):\n",
    "        if feature_names is None:\n",
    "            feature_names = ['trust', 'price']\n",
    "        \n",
    "        scaled_names = [f\"{name}_scaled\" for name in feature_names]\n",
    "        binned_names = [f\"{name}_binned\" for name in feature_names]\n",
    "        engineered_names = [\n",
    "            'trust_price_interaction',\n",
    "            'trust_squared',\n",
    "            'price_squared',\n",
    "            'trust_cubed',\n",
    "            'price_cubed',\n",
    "            'high_trust',\n",
    "            'high_price',\n",
    "            'low_trust',\n",
    "            'low_price'\n",
    "        ]\n",
    "        return np.array(scaled_names + binned_names + engineered_names)\n",
    "\n",
    "# Read and prepare data\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "categorical_features = [\n",
    "    'iag_business_unit_ug',\n",
    "    'iag_age_band_auto',\n",
    "    'iag_tenure_band_enum',\n",
    "    'iag_product_type_auto',\n",
    "    'iag_region_ug'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'iag_trust_confidence_scale11',\n",
    "    'iag_value_price_of_policy_reflects_scale11'\n",
    "]\n",
    "\n",
    "# Drop rows with missing values\n",
    "features_to_check = numeric_features + categorical_features\n",
    "df_clean = df.dropna(subset=features_to_check + ['Likely to recommend']).copy()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = EnhancedNumericTransformer()\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features)\n",
    ")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_clean[features_to_check]\n",
    "y = df_clean['Likely to recommend']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Calculate target class distribution\n",
    "class_counts = y_train.value_counts()\n",
    "n_samples_majority = class_counts.max()\n",
    "\n",
    "# Configure SMOTE for balanced but not completely equal classes\n",
    "sampling_strategy = {\n",
    "    'Detract': min(n_samples_majority, int(n_samples_majority * 0.8)),\n",
    "    'Passive': min(n_samples_majority, int(n_samples_majority * 0.9)),\n",
    "    'Super Detract': min(n_samples_majority, int(n_samples_majority * 0.8))\n",
    "}\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(\n",
    "    random_state=42,\n",
    "    sampling_strategy=sampling_strategy\n",
    ")\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Feature selection with increased max_iter\n",
    "selector = SelectFromModel(\n",
    "    LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        max_iter=3000,\n",
    "        class_weight='balanced',\n",
    "        C=0.1\n",
    "    ),\n",
    "    max_features=30\n",
    ")\n",
    "\n",
    "# Fit selector and transform data\n",
    "X_train_selected = selector.fit_transform(X_train_balanced, y_train_balanced)\n",
    "X_test_selected = selector.transform(X_test_transformed)\n",
    "\n",
    "# Final classifier with tuned parameters\n",
    "classifier = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    max_iter=3000,\n",
    "    class_weight='balanced',\n",
    "    solver='saga',  # Changed to saga for better convergence\n",
    "    random_state=42,\n",
    "    tol=1e-4,\n",
    "    C=0.1\n",
    ")\n",
    "\n",
    "# Fit the classifier\n",
    "classifier.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test_selected)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Model Performance:\\n\")\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f'True {c}' for c in classifier.classes_],\n",
    "    columns=[f'Pred {c}' for c in classifier.classes_]\n",
    "))\n",
    "\n",
    "# Print class distributions\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nBalanced class distribution:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming features...\n",
      "Transformed training data shape: (6765, 33)\n",
      "Applying SMOTE...\n",
      "Balanced training data shape: (14492, 33)\n",
      "Performing feature selection...\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'max_features' parameter of SelectFromModel must be an int in the range [0, inf), a callable or None. Got 'auto' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 240\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classifier, selector, preprocessor\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     classifier, selector, preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 169\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(df_path)\u001b[0m\n\u001b[0;32m    158\u001b[0m selector \u001b[38;5;241m=\u001b[39m SelectFromModel(\n\u001b[0;32m    159\u001b[0m     LogisticRegression(\n\u001b[0;32m    160\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Fit selector and transform data\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_balanced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m X_test_selected \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mtransform(X_test_transformed)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected features shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_selected\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32me:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32me:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32me:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1141\u001b[0m )\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1144\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Apps\\anaconda3\\envs\\iag\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'max_features' parameter of SelectFromModel must be an int in the range [0, inf), a callable or None. Got 'auto' instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class DomainFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        self.power_transformer.fit(X_array)\n",
    "        X_power = self.power_transformer.transform(X_array)\n",
    "        self.scaler.fit(X_power)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_array = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "        X_power = self.power_transformer.transform(X_array)\n",
    "        X_scaled = self.scaler.transform(X_power)\n",
    "        \n",
    "        trust_scores = X_array[:, 0]\n",
    "        price_scores = X_array[:, 1]\n",
    "        \n",
    "        # Domain-specific feature engineering\n",
    "        very_satisfied = (trust_scores >= 9) & (price_scores >= 8)\n",
    "        very_dissatisfied = (trust_scores <= 5) & (price_scores <= 5)\n",
    "        mixed_experience = np.abs(trust_scores - price_scores) >= 3\n",
    "        \n",
    "        # Create satisfaction segments\n",
    "        high_trust_low_price = (trust_scores >= 8) & (price_scores <= 6)\n",
    "        low_trust_high_price = (trust_scores <= 6) & (price_scores >= 8)\n",
    "        \n",
    "        # Relative satisfaction metrics\n",
    "        trust_to_price_ratio = trust_scores / (price_scores + 1)  # Add 1 to avoid division by zero\n",
    "        satisfaction_gap = trust_scores - price_scores\n",
    "        \n",
    "        # Combined satisfaction score\n",
    "        combined_score = (trust_scores * 0.6 + price_scores * 0.4)  # Weighted average\n",
    "        \n",
    "        # Create the feature matrix\n",
    "        features = np.column_stack([\n",
    "            X_scaled,\n",
    "            very_satisfied,\n",
    "            very_dissatisfied,\n",
    "            mixed_experience,\n",
    "            high_trust_low_price,\n",
    "            low_trust_high_price,\n",
    "            trust_to_price_ratio.reshape(-1, 1),\n",
    "            satisfaction_gap.reshape(-1, 1),\n",
    "            combined_score.reshape(-1, 1)\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def get_feature_names_out(self, feature_names=None):\n",
    "        base_names = ['trust_scaled', 'price_scaled']\n",
    "        engineered_names = [\n",
    "            'very_satisfied',\n",
    "            'very_dissatisfied',\n",
    "            'mixed_experience',\n",
    "            'high_trust_low_price',\n",
    "            'low_trust_high_price',\n",
    "            'trust_price_ratio',\n",
    "            'satisfaction_gap',\n",
    "            'combined_score'\n",
    "        ]\n",
    "        return np.array(base_names + engineered_names)\n",
    "\n",
    "def train_and_evaluate_model(df_path='../../data/IAG.xlsx'):\n",
    "    # Read and prepare data\n",
    "    df = pd.read_excel(df_path)\n",
    "    \n",
    "    categorical_features = [\n",
    "        'iag_business_unit_ug',\n",
    "        'iag_age_band_auto',\n",
    "        'iag_tenure_band_enum',\n",
    "        'iag_product_type_auto',\n",
    "        'iag_region_ug'\n",
    "    ]\n",
    "\n",
    "    numeric_features = [\n",
    "        'iag_trust_confidence_scale11',\n",
    "        'iag_value_price_of_policy_reflects_scale11'\n",
    "    ]\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    features_to_check = numeric_features + categorical_features\n",
    "    df_clean = df.dropna(subset=features_to_check + ['Likely to recommend']).copy()\n",
    "\n",
    "    # Create preprocessing pipelines\n",
    "    numeric_transformer = DomainFeatureTransformer()\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers\n",
    "    preprocessor = make_column_transformer(\n",
    "        (numeric_transformer, numeric_features),\n",
    "        (categorical_transformer, categorical_features)\n",
    "    )\n",
    "\n",
    "    # Prepare X and y\n",
    "    X = df_clean[features_to_check]\n",
    "    y = df_clean['Likely to recommend']\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Transform the data\n",
    "    print(\"Transforming features...\")\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    print(\"Transformed training data shape:\", X_train_transformed.shape)\n",
    "\n",
    "    # Calculate custom class weights\n",
    "    class_counts = y_train.value_counts()\n",
    "    total_samples = len(y_train)\n",
    "    class_weights = {\n",
    "        cls: (total_samples / (len(class_counts) * count)) ** 0.5\n",
    "        for cls, count in class_counts.items()\n",
    "    }\n",
    "\n",
    "    # Configure SMOTE with moderate balancing\n",
    "    sampling_strategy = {\n",
    "        'Detract': int(class_counts['Promote'] * 0.7),\n",
    "        'Passive': int(class_counts['Promote'] * 0.8),\n",
    "        'Super Detract': int(class_counts['Promote'] * 0.7)\n",
    "    }\n",
    "\n",
    "    # Apply SMOTE\n",
    "    print(\"Applying SMOTE...\")\n",
    "    smote = SMOTE(\n",
    "        random_state=42,\n",
    "        sampling_strategy=sampling_strategy\n",
    "    )\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_transformed, y_train)\n",
    "    print(\"Balanced training data shape:\", X_train_balanced.shape)\n",
    "\n",
    "    # Feature selection\n",
    "    print(\"Performing feature selection...\")\n",
    "    selector = SelectFromModel(\n",
    "        LogisticRegression(\n",
    "            multi_class='multinomial',\n",
    "            max_iter=3000,\n",
    "            class_weight='balanced',\n",
    "            C=0.1\n",
    "        ),\n",
    "        max_features='auto'\n",
    "    )\n",
    "\n",
    "    # Fit selector and transform data\n",
    "    X_train_selected = selector.fit_transform(X_train_balanced, y_train_balanced)\n",
    "    X_test_selected = selector.transform(X_test_transformed)\n",
    "    print(\"Selected features shape:\", X_train_selected.shape)\n",
    "\n",
    "    # Create base classifier\n",
    "    base_classifier = LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        max_iter=3000,\n",
    "        solver='saga',\n",
    "        random_state=42,\n",
    "        tol=1e-4,\n",
    "        C=0.1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Create calibrated classifier\n",
    "    print(\"Training calibrated classifier...\")\n",
    "    classifier = CalibratedClassifierCV(\n",
    "        base_classifier,\n",
    "        cv=5,\n",
    "        method='sigmoid'\n",
    "    )\n",
    "\n",
    "    # Fit the classifier\n",
    "    classifier.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test_selected)\n",
    "\n",
    "    # Print performance metrics\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(pd.DataFrame(\n",
    "        cm,\n",
    "        index=[f'True {c}' for c in classifier.classes_],\n",
    "        columns=[f'Pred {c}' for c in classifier.classes_]\n",
    "    ))\n",
    "\n",
    "    # Print class distributions\n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print(\"\\nBalanced class distribution:\")\n",
    "    print(pd.Series(y_train_balanced).value_counts())\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_names = (\n",
    "        list(numeric_transformer.get_feature_names_out()) + \n",
    "        [f\"{feat}_{val}\" for feat in categorical_features \n",
    "         for val in df_clean[feat].unique()[1:]]\n",
    "    )\n",
    "    \n",
    "    # Print feature importance\n",
    "    print(\"\\nTop 15 Most Important Features:\")\n",
    "    feature_importances = np.abs(selector.estimator_.coef_).mean(axis=0)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names[:len(feature_importances)],\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    print(importance_df.head(15))\n",
    "\n",
    "    return classifier, selector, preprocessor\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Train and evaluate the model\n",
    "    classifier, selector, preprocessor = train_and_evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
