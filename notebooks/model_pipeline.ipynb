{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 9264 samples after removing missing target values\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.819\n",
      "ROC AUC: 0.885\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "0              0.741403  0.706393  0.723474  3113.000000\n",
      "1              0.854875  0.875305  0.864969  6151.000000\n",
      "accuracy       0.818545  0.818545  0.818545     0.818545\n",
      "macro avg      0.798139  0.790849  0.794222  9264.000000\n",
      "weighted avg   0.816744  0.818545  0.817422  9264.000000\n",
      "Model saved to: e:\\vscode projects\\iag_analysis\\iag analysis 2\\sql\\model_sklearn\\promotion_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "\n",
    "save_dir = './model_sklearn'  # relative to current notebook location\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "class CustomBinner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bins, labels):\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # Convert to numpy array if it's a DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0].values\n",
    "        elif isinstance(X, pd.Series):\n",
    "            X = X.values\n",
    "            \n",
    "        # Ensure we have a 1D array\n",
    "        if X.ndim > 1 and X.shape[1] == 1:\n",
    "            X = X.ravel()\n",
    "            \n",
    "        # Perform binning\n",
    "        binned = pd.cut(X, bins=self.bins, labels=self.labels)\n",
    "        \n",
    "        # Convert to DataFrame for compatibility\n",
    "        return pd.DataFrame(binned)\n",
    "\n",
    "def create_preprocessing_pipeline():\n",
    "    # Define binning parameters\n",
    "    trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "    trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "    price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "    price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "    \n",
    "    # Create numeric transformers with binning AND encoding\n",
    "    trust_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('binner', CustomBinner(bins=trust_bins, labels=trust_labels)),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    price_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('binner', CustomBinner(bins=price_bins, labels=price_labels)),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Create categorical transformer\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('encoder', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Define feature groups\n",
    "    numeric_features = {\n",
    "        'trust': ['iag_trust_confidence_scale11'],\n",
    "        'price': ['iag_value_price_of_policy_reflects_scale11']\n",
    "    }\n",
    "    \n",
    "    categorical_features = [\n",
    "        'iag_business_unit_ug',\n",
    "        'iag_age_band_auto',\n",
    "        'iag_tenure_band_enum',\n",
    "        'iag_product_type_auto',\n",
    "        'iag_region_ug'\n",
    "    ]\n",
    "    \n",
    "    # Create the column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('trust', trust_transformer, numeric_features['trust']),\n",
    "            ('price', price_transformer, numeric_features['price']),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        verbose_feature_names_out=False  # Simplified feature names\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def create_full_pipeline():\n",
    "    preprocessor = create_preprocessing_pipeline()\n",
    "    \n",
    "    # Create full pipeline with logistic regression\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.pipeline = create_full_pipeline()\n",
    "        self.feature_columns = [\n",
    "            'iag_trust_confidence_scale11',\n",
    "            'iag_value_price_of_policy_reflects_scale11',\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "        \n",
    "    def prepare_target(self, df):\n",
    "        return (df['Likely to recommend'] == 'Promote').astype(int)\n",
    "        \n",
    "    def fit_and_evaluate(self, df):\n",
    "        # Prepare features and target\n",
    "        X = df[self.feature_columns]\n",
    "        y = self.prepare_target(df)\n",
    "        \n",
    "        # Handle missing values in target\n",
    "        mask = ~pd.isna(y)\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        print(f\"Training with {len(X)} samples after removing missing target values\")\n",
    "        \n",
    "        # Fit pipeline\n",
    "        self.pipeline.fit(X, y)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.pipeline.predict(X)\n",
    "        y_pred_proba = self.pipeline.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': (y_pred == y).mean(),\n",
    "            'roc_auc': roc_auc_score(y, y_pred_proba),\n",
    "            'classification_report': classification_report(y, y_pred, output_dict=True)\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def get_feature_columns(self):\n",
    "        return self.feature_columns\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_excel('../../data/IAG.xlsx')\n",
    "    \n",
    "    # Initialize and train model\n",
    "    trainer = ModelTrainer()\n",
    "    metrics = trainer.fit_and_evaluate(df)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(pd.DataFrame(metrics['classification_report']).transpose())\n",
    "    \n",
    "    # Save pipeline\n",
    "    import joblib\n",
    "    model_path = os.path.join(save_dir, 'promotion_pipeline.joblib')\n",
    "    joblib.dump(trainer.pipeline, model_path)\n",
    "    print(f\"Model saved to: {os.path.abspath(model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Starting data preparation...\n",
      "\n",
      "Shape after dropping missing values: (8457, 48)\n",
      "\n",
      "Unique values in binned features:\n",
      "Trust bins: iag_trust_confidence_binned\n",
      "Very High    3645\n",
      "High         1551\n",
      "Moderate     1435\n",
      "Low           972\n",
      "Very Low      854\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Price bins: iag_value_price_binned\n",
      "Excellent    4065\n",
      "Very Good    1639\n",
      "Poor         1154\n",
      "Good         1040\n",
      "Fair          559\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fitting model with 32 features...\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.388857\n",
      "         Iterations: 273\n",
      "         Function evaluations: 274\n",
      "         Gradient evaluations: 274\n",
      "\n",
      "Significant Features (p < 0.05):\n",
      "                                  Feature  Coefficient        P_Value  \\\n",
      "4   iag_trust_confidence_binned_Very High     4.159600  2.668145e-146   \n",
      "3        iag_trust_confidence_binned_High     3.101562   1.858237e-87   \n",
      "2    iag_trust_confidence_binned_Moderate     2.028339   3.219937e-41   \n",
      "8        iag_value_price_binned_Excellent     1.502706   2.081850e-36   \n",
      "1         iag_trust_confidence_binned_Low     1.289624   9.311580e-17   \n",
      "0                                   const    -2.388303   1.099691e-10   \n",
      "30      iag_region_ug_Consumer Claims Ops     0.389568   2.788184e-07   \n",
      "7        iag_value_price_binned_Very Good     0.515470   5.708071e-06   \n",
      "29           iag_product_type_auto_Wheels    -1.075018   1.153310e-02   \n",
      "23        iag_product_type_auto_Home Pack    -0.733326   1.899968e-02   \n",
      "28          iag_product_type_auto_Vehicle    -0.514735   2.934278e-02   \n",
      "9         iag_business_unit_ug_Operations    -0.297514   4.149082e-02   \n",
      "\n",
      "    Odds_Ratio  \n",
      "4    64.045900  \n",
      "3    22.232644  \n",
      "2     7.601451  \n",
      "8     4.493831  \n",
      "1     3.631421  \n",
      "0     0.091785  \n",
      "30    1.476343  \n",
      "7     1.674425  \n",
      "29    0.341292  \n",
      "23    0.480309  \n",
      "28    0.597659  \n",
      "9     0.742662  \n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.826\n",
      "ROC AUC: 0.889\n",
      "McFadden's Pseudo R-squared: 0.387\n",
      "\n",
      "Model saved to: e:\\vscode projects\\iag_analysis\\iag analysis 2\\sql\\model_statsmodels\\recommendation_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create directory for statsmodels\n",
    "save_dir = './model_statsmodels'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "class StatsmodelsRecommendationPipeline:\n",
    "    def __init__(self):\n",
    "        self.trust_bins = [-np.inf, 5, 7, 8, 9, np.inf]\n",
    "        self.trust_labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']\n",
    "        \n",
    "        self.price_bins = [-np.inf, 5, 6, 7, 8, np.inf]\n",
    "        self.price_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "        \n",
    "        self.features = [\n",
    "            'iag_trust_confidence_scale11',\n",
    "            'iag_value_price_of_policy_reflects_scale11',\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def prepare_data(self, df):\n",
    "        print(\"\\nStarting data preparation...\")\n",
    "        \n",
    "        # Create copy and drop missing values\n",
    "        df_clean = df.copy()\n",
    "        df_clean = df_clean.dropna(subset=self.features + ['Likely to recommend'])\n",
    "        \n",
    "        print(\"\\nShape after dropping missing values:\", df_clean.shape)\n",
    "        \n",
    "        # Create binned versions of numeric features\n",
    "        df_clean['iag_trust_confidence_binned'] = pd.cut(\n",
    "            df_clean['iag_trust_confidence_scale11'].astype(float),\n",
    "            bins=self.trust_bins,\n",
    "            labels=self.trust_labels\n",
    "        )\n",
    "        \n",
    "        df_clean['iag_value_price_binned'] = pd.cut(\n",
    "            df_clean['iag_value_price_of_policy_reflects_scale11'].astype(float),\n",
    "            bins=self.price_bins,\n",
    "            labels=self.price_labels\n",
    "        )\n",
    "        \n",
    "        print(\"\\nUnique values in binned features:\")\n",
    "        print(\"Trust bins:\", df_clean['iag_trust_confidence_binned'].value_counts())\n",
    "        print(\"\\nPrice bins:\", df_clean['iag_value_price_binned'].value_counts())\n",
    "        \n",
    "        # Define categorical features including binned ones\n",
    "        categorical_features = [\n",
    "            'iag_trust_confidence_binned',\n",
    "            'iag_value_price_binned',\n",
    "            'iag_business_unit_ug',\n",
    "            'iag_age_band_auto',\n",
    "            'iag_tenure_band_enum',\n",
    "            'iag_product_type_auto',\n",
    "            'iag_region_ug'\n",
    "        ]\n",
    "        \n",
    "        # Create dummies with proper prefixes\n",
    "        X = pd.get_dummies(df_clean[categorical_features], drop_first=True)\n",
    "        \n",
    "        # Store feature names for prediction\n",
    "        self.feature_names = X.columns.tolist()\n",
    "        \n",
    "        # Convert all columns to float64\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        # Add constant\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Convert target to binary\n",
    "        y = (df_clean['Likely to recommend'] == 'Promote').astype(np.int64)\n",
    "        \n",
    "        return X, y, df_clean\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        try:\n",
    "            print(f\"\\nFitting model with {X.shape[1]} features...\")\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "            y_np = y.to_numpy(dtype=np.int64)\n",
    "            \n",
    "            # Fit model\n",
    "            model = sm.Logit(y_np, X_np)\n",
    "            self.model = model.fit(method='bfgs', maxiter=1000)\n",
    "            \n",
    "            return self.model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Model fitting failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def predict(self, X, preprocessed=False):\n",
    "        \"\"\"Make predictions on new data\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted first\")\n",
    "            \n",
    "        if preprocessed:\n",
    "            # Data is already processed, just ensure constant\n",
    "            if 'const' not in X.columns:\n",
    "                X = sm.add_constant(X)\n",
    "            X_np = X.to_numpy(dtype=np.float64)\n",
    "        else:\n",
    "            # Process new data the same way as training data\n",
    "            df_clean = X.copy()\n",
    "            \n",
    "            # Create binned versions\n",
    "            df_clean['iag_trust_confidence_binned'] = pd.cut(\n",
    "                df_clean['iag_trust_confidence_scale11'].astype(float),\n",
    "                bins=self.trust_bins,\n",
    "                labels=self.trust_labels\n",
    "            )\n",
    "            \n",
    "            df_clean['iag_value_price_binned'] = pd.cut(\n",
    "                df_clean['iag_value_price_of_policy_reflects_scale11'].astype(float),\n",
    "                bins=self.price_bins,\n",
    "                labels=self.price_labels\n",
    "            )\n",
    "            \n",
    "            # Create dummies\n",
    "            categorical_features = [\n",
    "                'iag_trust_confidence_binned',\n",
    "                'iag_value_price_binned',\n",
    "                'iag_business_unit_ug',\n",
    "                'iag_age_band_auto',\n",
    "                'iag_tenure_band_enum',\n",
    "                'iag_product_type_auto',\n",
    "                'iag_region_ug'\n",
    "            ]\n",
    "            \n",
    "            X_processed = pd.get_dummies(df_clean[categorical_features], drop_first=True)\n",
    "            \n",
    "            # Ensure all training features are present\n",
    "            for feature in self.feature_names:\n",
    "                if feature not in X_processed.columns:\n",
    "                    X_processed[feature] = 0\n",
    "                    \n",
    "            # Reorder columns to match training data\n",
    "            X_processed = X_processed[self.feature_names]\n",
    "            \n",
    "            # Add constant\n",
    "            X_processed = sm.add_constant(X_processed)\n",
    "            X_np = X_processed.to_numpy(dtype=np.float64)\n",
    "            \n",
    "        # Make predictions\n",
    "        y_pred_proba = self.model.predict(X_np)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        return y_pred, y_pred_proba\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        # Use preprocessed=True since X is already processed during training\n",
    "        y_pred, y_pred_proba = self.predict(X, preprocessed=True)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': (y_pred == y).mean(),\n",
    "            'roc_auc': roc_auc_score(y, y_pred_proba),\n",
    "            'classification_report': classification_report(y, y_pred, output_dict=True),\n",
    "            'pseudo_r2': self.model.prsquared\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance metrics\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted first\")\n",
    "            \n",
    "        feature_names = ['const'] + self.feature_names\n",
    "        \n",
    "        summary_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': self.model.params,\n",
    "            'P_Value': self.model.pvalues,\n",
    "            'Odds_Ratio': np.exp(self.model.params)\n",
    "        }).sort_values('P_Value')\n",
    "        \n",
    "        return summary_df\n",
    "\n",
    "# Training and evaluation\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_excel('../../data/IAG.xlsx')\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = StatsmodelsRecommendationPipeline()\n",
    "\n",
    "# Prepare data\n",
    "X, y, df_clean = pipeline.prepare_data(df)\n",
    "\n",
    "# Fit model\n",
    "model = pipeline.fit(X, y)\n",
    "\n",
    "if model is not None:\n",
    "    # Get feature importance\n",
    "    feature_importance = pipeline.get_feature_importance()\n",
    "    print(\"\\nSignificant Features (p < 0.05):\")\n",
    "    significant_features = feature_importance[feature_importance['P_Value'] < 0.05]\n",
    "    print(significant_features[['Feature', 'Coefficient', 'P_Value', 'Odds_Ratio']])\n",
    "    \n",
    "    # Get performance metrics\n",
    "    metrics = pipeline.evaluate(X, y)\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "    print(f\"McFadden's Pseudo R-squared: {metrics['pseudo_r2']:.3f}\")\n",
    "    \n",
    "    # Save the pipeline\n",
    "    model_path = os.path.join(save_dir, 'recommendation_pipeline.pkl')\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "    print(f\"\\nModel saved to: {os.path.abspath(model_path)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Model fitting failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
